{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":66653,"databundleVersionId":7500999,"sourceType":"competition"}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup ","metadata":{}},{"cell_type":"code","source":"SYS_INPUT_DIR = '/kaggle/input/pii-detection-removal-from-educational-data'","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:10.044991Z","iopub.execute_input":"2024-01-30T10:26:10.045485Z","iopub.status.idle":"2024-01-30T10:26:10.052764Z","shell.execute_reply.started":"2024-01-30T10:26:10.045453Z","shell.execute_reply":"2024-01-30T10:26:10.051501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport warnings\nimport pandas as pd\n\nwarnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 1000)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:10.054995Z","iopub.execute_input":"2024-01-30T10:26:10.0555Z","iopub.status.idle":"2024-01-30T10:26:10.075091Z","shell.execute_reply.started":"2024-01-30T10:26:10.055464Z","shell.execute_reply":"2024-01-30T10:26:10.073838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read train data","metadata":{}},{"cell_type":"code","source":"import json\ntrain_json = json.load(open(os.path.join(SYS_INPUT_DIR, \"train.json\")))\ntrain = pd.json_normalize(train_json)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:10.077152Z","iopub.execute_input":"2024-01-30T10:26:10.078237Z","iopub.status.idle":"2024-01-30T10:26:13.028161Z","shell.execute_reply.started":"2024-01-30T10:26:10.078058Z","shell.execute_reply":"2024-01-30T10:26:13.026789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:13.031294Z","iopub.execute_input":"2024-01-30T10:26:13.031836Z","iopub.status.idle":"2024-01-30T10:26:13.070478Z","shell.execute_reply.started":"2024-01-30T10:26:13.031788Z","shell.execute_reply":"2024-01-30T10:26:13.068575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check train has one row per document\nassert train['document'].nunique() == train.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:13.072988Z","iopub.execute_input":"2024-01-30T10:26:13.073785Z","iopub.status.idle":"2024-01-30T10:26:13.095069Z","shell.execute_reply.started":"2024-01-30T10:26:13.073747Z","shell.execute_reply":"2024-01-30T10:26:13.093939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_ner_labels = [\n    'B-NAME_STUDENT', 'I-NAME_STUDENT',\n    'B-URL_PERSONAL', 'I-URL_PERSONAL',\n    'B-ID_NUM', 'I-ID_NUM',\n    'B-EMAIL', 'I-EMAIL',\n    'B-STREET_ADDRESS', 'I-STREET_ADDRESS',\n    'B-PHONE_NUM', 'I-PHONE_NUM',\n    'B-USERNAME', 'I-USERNAME'\n]","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:13.096847Z","iopub.execute_input":"2024-01-30T10:26:13.097438Z","iopub.status.idle":"2024-01-30T10:26:13.118963Z","shell.execute_reply.started":"2024-01-30T10:26:13.097404Z","shell.execute_reply":"2024-01-30T10:26:13.117808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calculate stats","metadata":{}},{"cell_type":"code","source":"train_eda = train.copy()\n# Find documnets with high number of entities\ntrain_eda['ner_labels'] = train_eda['labels'].apply(lambda x: [item for item in x if item != 'O'])\ntrain_eda['count_ner_labels'] = train_eda['ner_labels'].apply(len)\ntrain_eda['count_distinct_ner_labels'] = train_eda['ner_labels'].apply(lambda x: len(set(x)))\ntrain_eda.sort_values(by='count_distinct_ner_labels', inplace=True, ascending=False)\n\nexploded_df = train_eda['ner_labels'].explode()\ndummies = pd.get_dummies(exploded_df).reset_index()\n\nfrequency = dummies.sum().sort_values(ascending=False)\nordered_columns = frequency.index.tolist() ; ordered_columns.remove(\"index\")\n\ncounted = dummies.groupby('index').sum()\ncounted = counted.reindex(columns=full_ner_labels, fill_value=0)\ncounted = counted[ordered_columns + [i for i in full_ner_labels if i not in ordered_columns]]\n\ntrain_eda = train_eda.join(counted)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:13.121177Z","iopub.execute_input":"2024-01-30T10:26:13.121717Z","iopub.status.idle":"2024-01-30T10:26:13.430925Z","shell.execute_reply.started":"2024-01-30T10:26:13.121673Z","shell.execute_reply":"2024-01-30T10:26:13.429217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explore most interesting documents\n\nInteresting documents are those with many distinct NER labels","metadata":{}},{"cell_type":"code","source":"sample_train = train_eda.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:13.432724Z","iopub.execute_input":"2024-01-30T10:26:13.433266Z","iopub.status.idle":"2024-01-30T10:26:13.441663Z","shell.execute_reply.started":"2024-01-30T10:26:13.433219Z","shell.execute_reply":"2024-01-30T10:26:13.440299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Display functions","metadata":{}},{"cell_type":"code","source":"from bs4 import BeautifulSoup\n\nner_colors = {\n    'B-NAME_STUDENT': 'rgb(255, 179, 179)',\n    'I-NAME_STUDENT': 'rgb(139, 0, 0)',\n    'B-URL_PERSONAL': 'rgb(255, 223, 179)',\n    'I-URL_PERSONAL': 'rgb(255, 140, 0)',\n    'B-ID_NUM': 'rgb((255, 255, 179)',\n    'I-ID_NUM':  'rgb(204, 204, 0)',\n    'B-EMAIL': 'rgb(179, 255, 179)',\n    'I-EMAIL': 'rgb(0, 100, 0)',\n    'B-STREET_ADDRESS':  'rgb(179, 223, 255)',\n    'I-STREET_ADDRESS': 'rgb(0, 0, 139)',\n    'B-PHONE_NUM': 'rgb(223, 179, 255)',\n    'I-PHONE_NUM': 'rgb(75, 0, 130)',\n    'B-USERNAME': 'rgb(255, 179, 223)',\n    'I-USERNAME': 'rgb(231, 84, 128)',\n}\n\ndef generate_legend():\n    legend_html = '<div class=\"legend\" style=\"margin-bottom: 10px;\">'\n    for entity, color in ner_colors.items():\n        legend_html += f'<span style=\"color: {color}; margin-right: 10px;\">{entity}</span>'\n    legend_html += '</div>'\n    return legend_html\n\ndef highlight_entities(text, tokens, labels):\n    legend = generate_legend()  # Generate the legend\n    soup = BeautifulSoup(legend, 'html.parser')  # Start with the legend\n\n    last_idx = 0\n    for token, label in zip(tokens, labels):\n        start, end = text.find(token, last_idx), text.find(token, last_idx) + len(token)\n\n        if start != -1:\n            soup.append(BeautifulSoup(text[last_idx:start], 'html.parser'))\n\n            if label != 'O':\n                token_span = soup.new_tag('span', style=f'background-color: {ner_colors.get(label, \"black\")}; font-family: \"Tahoma\"; padding: 0 2px; border-radius: 3px;')\n                token_span.string = token\n                soup.append(token_span)\n                \n                label_span = soup.new_tag('span', style=f'background-color: {ner_colors.get(label, \"black\")}; font-family: Tahoma; font-weight: bold; padding: 0 2px; border-radius: 3px;')\n                label_span.string = f\" [{label}]\"\n                soup.append(label_span)\n            else:\n                  soup.append(token)\n\n            last_idx = end\n\n    soup.append(BeautifulSoup(text[last_idx:], 'html.parser'))\n    return str(soup).replace('\\n', '<br/>')\n\ndef label_color(label):\n    return ner_colors.get(label, 'black')  # Default color","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:13.449765Z","iopub.execute_input":"2024-01-30T10:26:13.450362Z","iopub.status.idle":"2024-01-30T10:26:13.4672Z","shell.execute_reply.started":"2024-01-30T10:26:13.450313Z","shell.execute_reply":"2024-01-30T10:26:13.465573Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Display top interesting documents","metadata":{}},{"cell_type":"code","source":"sample_train.loc[:, 'html'] = sample_train.apply(lambda x: highlight_entities(x['full_text'], x['tokens'], x['labels']), axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:13.469048Z","iopub.execute_input":"2024-01-30T10:26:13.46971Z","iopub.status.idle":"2024-01-30T10:26:13.688055Z","shell.execute_reply.started":"2024-01-30T10:26:13.469659Z","shell.execute_reply":"2024-01-30T10:26:13.686602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display, HTML\n\nfor html in sample_train['html']:\n    display(HTML(html))","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:13.690008Z","iopub.execute_input":"2024-01-30T10:26:13.690843Z","iopub.status.idle":"2024-01-30T10:26:13.710594Z","shell.execute_reply.started":"2024-01-30T10:26:13.690791Z","shell.execute_reply":"2024-01-30T10:26:13.708647Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can adjust coloring in ner_colors dictionary","metadata":{}},{"cell_type":"markdown","source":"# NER labels data distribution","metadata":{}},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"import pandas \n\nnum_documents = train_eda.shape[0]\nner_labels_data = train_eda[full_ner_labels].melt(var_name='ner_label', value_name='count')\nner_labels_stat = ner_labels_data.groupby('ner_label').agg(\n    doc_count=pd.NamedAgg(column='count', aggfunc=lambda x: (x > 0).sum()),\n    ner_count=pd.NamedAgg(column='count', aggfunc=\"sum\"),\n).reset_index()\nner_labels_stat['doc_count_percentage'] = np.round(ner_labels_stat['doc_count'] /num_documents,4)\nner_labels_stat['ner_count_percentage'] = np.round(ner_labels_stat['ner_count'] /sum(ner_labels_stat['ner_count']),4)\n\nner_labels_stat = ner_labels_stat.sort_values('doc_count', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:13.71324Z","iopub.execute_input":"2024-01-30T10:26:13.71383Z","iopub.status.idle":"2024-01-30T10:26:13.771515Z","shell.execute_reply.started":"2024-01-30T10:26:13.713782Z","shell.execute_reply":"2024-01-30T10:26:13.769817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ner_labels_stat","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:13.7738Z","iopub.execute_input":"2024-01-30T10:26:13.774389Z","iopub.status.idle":"2024-01-30T10:26:13.795919Z","shell.execute_reply.started":"2024-01-30T10:26:13.774338Z","shell.execute_reply":"2024-01-30T10:26:13.79372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot function","metadata":{}},{"cell_type":"code","source":"def plot_ner_distribution(ner_labels_stat, count_col, percentage_col):\n    \n    import numpy as np\n    import matplotlib.pyplot as plt\n    import matplotlib.colors as mcolors\n    \n    plt.figure(figsize=(16,8))\n    unique_labels = ner_labels_stat['ner_label'].unique()\n    colors = plt.cm.hsv(np.linspace(0, 1, len(unique_labels)))\n    color_dict = dict(zip(unique_labels, colors))\n    \n    for label in unique_labels:\n        subset = ner_labels_stat[ner_labels_stat['ner_label'] == label]\n        plt.bar(subset['ner_label'], subset[count_col], color=color_dict[label])\n        \n    plt.ylabel('Count')\n    plt.xticks(rotation=45)\n    \n    # Create secondary y-axis for percentage\n    sec_axis = plt.twinx()\n    sec_axis.plot(ner_labels_stat['ner_label'], ner_labels_stat[percentage_col], color='r')\n    sec_axis.set_ylabel('Percentage')\n    \n    # Titles and labels\n    plt.title('Count / Percentage of NER Labels')\n    plt.xlabel('NER Label')","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:13.798633Z","iopub.execute_input":"2024-01-30T10:26:13.799379Z","iopub.status.idle":"2024-01-30T10:26:13.813861Z","shell.execute_reply.started":"2024-01-30T10:26:13.799326Z","shell.execute_reply":"2024-01-30T10:26:13.812065Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## NER labels vs. Number of documents","metadata":{}},{"cell_type":"code","source":"plot_ner_distribution(ner_labels_stat, 'doc_count', 'doc_count_percentage')","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:13.816401Z","iopub.execute_input":"2024-01-30T10:26:13.816907Z","iopub.status.idle":"2024-01-30T10:26:14.631932Z","shell.execute_reply.started":"2024-01-30T10:26:13.816868Z","shell.execute_reply":"2024-01-30T10:26:14.630517Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## NER labels distributions","metadata":{}},{"cell_type":"code","source":"plot_ner_distribution(ner_labels_stat, 'ner_count', 'ner_count_percentage')","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:14.633232Z","iopub.execute_input":"2024-01-30T10:26:14.634538Z","iopub.status.idle":"2024-01-30T10:26:15.440847Z","shell.execute_reply.started":"2024-01-30T10:26:14.634486Z","shell.execute_reply":"2024-01-30T10:26:15.439495Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NER label vs. POS tag correlation","metadata":{}},{"cell_type":"code","source":"import spacy\n\n# Load the spaCy model\nnlp = spacy.load(\"en_core_web_sm\")","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:15.443008Z","iopub.execute_input":"2024-01-30T10:26:15.444375Z","iopub.status.idle":"2024-01-30T10:26:16.839283Z","shell.execute_reply.started":"2024-01-30T10:26:15.444314Z","shell.execute_reply":"2024-01-30T10:26:16.837322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_eda_ner_vs_pos = train_eda[train_eda['count_ner_labels'] > 0][['document','tokens','labels','ner_labels']]\n\ntrain_eda_ner_vs_pos['pos_text'] = train_eda_ner_vs_pos.apply(lambda row: ' '.join([token for token, label in zip(row['tokens'], row['labels']) if label != 'O']), axis=1)\ndocs = nlp.pipe(train_eda_ner_vs_pos['pos_text'])\ntrain_eda_ner_vs_pos['pos_tags'] = [[token.pos_ for token in doc] for doc in docs]\ntrain_eda_ner_vs_pos.drop(columns=['pos_text'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:16.841323Z","iopub.execute_input":"2024-01-30T10:26:16.841791Z","iopub.status.idle":"2024-01-30T10:26:17.876965Z","shell.execute_reply.started":"2024-01-30T10:26:16.841757Z","shell.execute_reply":"2024-01-30T10:26:17.875128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exploded_df = train_eda_ner_vs_pos[['ner_labels', 'pos_tags']].apply(pd.Series.explode).reset_index(drop=True)\npivot_table = pd.pivot_table(exploded_df, index='ner_labels', columns='pos_tags', aggfunc=len, fill_value=0)\npivot_percentages = pivot_table.div(pivot_table.sum(axis=1), axis=0) * 100","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:17.879321Z","iopub.execute_input":"2024-01-30T10:26:17.879819Z","iopub.status.idle":"2024-01-30T10:26:17.904725Z","shell.execute_reply.started":"2024-01-30T10:26:17.879783Z","shell.execute_reply":"2024-01-30T10:26:17.903776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Create the figure and axis\nfig, ax = plt.subplots(figsize=(12, 12))\n\n# Create the heatmap using imshow, with pivot_percentages\ncax = ax.imshow(pivot_percentages, cmap=\"YlOrBr\", aspect='auto')\n\n# Add color bar at the top\ncbar = fig.colorbar(cax, ax=ax, location='top', fraction=0.05, pad=0.04)\ncbar.set_label('Percentage (%)', labelpad=10)\n\n# Set the tick labels for the bottom and top X-axis\nax.set_xticks(np.arange(len(pivot_percentages.columns)))\nax.set_xticklabels(pivot_percentages.columns)\nplt.xticks(rotation=90)\n\n# Set the tick labels for the left and right Y-axis\nax.set_yticks(np.arange(len(pivot_percentages.index)))\nax.set_yticklabels(pivot_percentages.index)\n\n# Display ticks and labels on the top and right axes\nax.tick_params(top=True, labeltop=True, right=True, labelright=True)\n\n# Annotate the heatmap with percentage values and counts in round brackets\nfor i in range(len(pivot_percentages.index)):\n    for j in range(len(pivot_percentages.columns)):\n        percentage = f\"{pivot_percentages.iloc[i, j]:.1f}%\"\n        count = f\"({pivot_table.iloc[i, j]})\"\n        ax.text(j, i, f\"{percentage}\\n{count}\", ha=\"center\", va=\"center\", color=\"black\", fontsize=9)\n\n# Add labels and a title\nax.set_xlabel('POS Tags', labelpad=20)  # labelpad adds padding to the label\nax.xaxis.set_label_position('top')  # Position the X-axis label at the top\nax.set_ylabel('NER Labels', labelpad=20)  # labelpad adds padding to the label\nax.yaxis.set_label_position('right')  # Position the Y-axis label on the right\nax.set_title('Percentage and Count of NER Label per POS Tag')\n\nplt.show();\n","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-01-30T10:26:17.90607Z","iopub.execute_input":"2024-01-30T10:26:17.907036Z","iopub.status.idle":"2024-01-30T10:26:19.641Z","shell.execute_reply.started":"2024-01-30T10:26:17.906997Z","shell.execute_reply":"2024-01-30T10:26:19.639332Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train vs Test token distribution\n\nThe test data is very limited, making any visualization appear less meaningful. However, once you acquire more extensive test or unlabeled data, calculating joint tokens could be useful.","metadata":{}},{"cell_type":"code","source":"import json\ntest_json = json.load(open(os.path.join(SYS_INPUT_DIR, \"test.json\")))\ntest = pd.json_normalize(test_json)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:19.642941Z","iopub.execute_input":"2024-01-30T10:26:19.643452Z","iopub.status.idle":"2024-01-30T10:26:19.656329Z","shell.execute_reply.started":"2024-01-30T10:26:19.643407Z","shell.execute_reply":"2024-01-30T10:26:19.654813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ner_label = 'B-NAME_STUDENT'","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:19.658106Z","iopub.execute_input":"2024-01-30T10:26:19.65882Z","iopub.status.idle":"2024-01-30T10:26:19.667771Z","shell.execute_reply.started":"2024-01-30T10:26:19.658783Z","shell.execute_reply":"2024-01-30T10:26:19.666366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_eda_ner_label = train_eda[train_eda[input_ner_label] > 0][['document','tokens','labels', input_ner_label]]\n\ndef process_row(row, value):\n    selected_indices = [i for i, x in enumerate(row['labels']) if x == value]\n    selected_values = [row['tokens'][i] for i in selected_indices]\n    return pd.Series([selected_indices, selected_values])\n    \ntrain_eda_ner_label[['ner_label_idxs','ner_label_tokens']] = train_eda_ner_label.apply(process_row, axis=1, value=input_ner_label)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:19.669459Z","iopub.execute_input":"2024-01-30T10:26:19.66989Z","iopub.status.idle":"2024-01-30T10:26:20.01175Z","shell.execute_reply.started":"2024-01-30T10:26:19.669854Z","shell.execute_reply":"2024-01-30T10:26:20.009161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_eda_ner_label = test.copy()\ntest_eda_ner_label['ner_label_tokens'] = train_eda_ner_label['ner_label_tokens']\ntest_eda_ner_label['joint_tokens'] = test_eda_ner_label.apply(lambda row: list(set(row['tokens']) & set(row['ner_label_tokens'])), axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:20.017921Z","iopub.execute_input":"2024-01-30T10:26:20.018499Z","iopub.status.idle":"2024-01-30T10:26:20.031348Z","shell.execute_reply.started":"2024-01-30T10:26:20.018433Z","shell.execute_reply":"2024-01-30T10:26:20.030058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_eda_ner_label","metadata":{"execution":{"iopub.status.busy":"2024-01-30T10:26:20.032883Z","iopub.execute_input":"2024-01-30T10:26:20.033268Z","iopub.status.idle":"2024-01-30T10:26:20.09503Z","shell.execute_reply.started":"2024-01-30T10:26:20.033238Z","shell.execute_reply":"2024-01-30T10:26:20.093577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# To be continued ...\n\nLooks like it's time to find more data and start building some model","metadata":{}},{"cell_type":"markdown","source":"Please share in comments any useful EDA techniques that you find interesting and would like to see implemented","metadata":{}}]}