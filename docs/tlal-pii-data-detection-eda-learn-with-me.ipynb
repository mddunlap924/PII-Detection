{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":66653,"databundleVersionId":7500999,"sourceType":"competition"},{"sourceId":3976,"sourceType":"datasetVersion","datasetId":2367},{"sourceId":7651,"sourceType":"datasetVersion","datasetId":13},{"sourceId":7457180,"sourceType":"datasetVersion","datasetId":4313900}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":126.292875,"end_time":"2024-02-10T16:14:16.444202","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-10T16:12:10.151327","version":"2.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Run this to enable CSS types\nfrom IPython.core.display import HTML\ndef css_styling():\n    styles = open(\"/kaggle/input/my-css-styles/kaggle_styles.css\", \"r\").read()\n    return HTML(\"<style>\"+styles+\"</style>\")\ncss_styling()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"papermill":{"duration":0.044329,"end_time":"2024-02-10T16:12:14.720653","exception":false,"start_time":"2024-02-10T16:12:14.676324","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-17T18:45:54.72329Z","iopub.execute_input":"2024-02-17T18:45:54.724502Z","iopub.status.idle":"2024-02-17T18:45:54.745549Z","shell.execute_reply.started":"2024-02-17T18:45:54.724439Z","shell.execute_reply":"2024-02-17T18:45:54.744085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<br>\n<div style=\"background-color: #f8d2b0; padding: 25px 25px; text-align: center;\">\n    <img src=\"https://www.thequestchallenge.org/static/images/mainlogo.png\" alt=\"Notebook Header Image\" style=\"padding-top: 25px 0 0 0;\">\n    <br><br>\n    <span style=\"font-family: Verdana; font-size: 32px; font-weight: bold; color: #EB7550; font-variant: small-caps; letter-spacing: 2px;\">\n        PII DATA DETECTION\n    </span>\n    <br><br>\n    <span style=\"font-size: 20px; color: white; letter-spacing: 2px; font-weight: bold;\">\n        üìöLEARNüìö &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; üî≠EDAüî≠ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ü§ñBASELINEü§ñ\n    </span>\n    <br><br>\n    <span style=\"font-family: Verdana; font-size: 12px; font-weight: bold; color: white;\">\n        CREATED BY: DARIEN SCHETTLER\n    </span>\n</div>\n\n<hr>\n\n<center><div class=\"alert alert-block alert-danger\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 18px;\">üõë &nbsp; WARNING:</b><br><br><b>THIS IS A WORK IN PROGRESS</b><br>\n</div></center>\n\n<center><div class=\"alert alert-block alert-warning\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 18px;\">üëè &nbsp; IF YOU FORK THIS OR FIND THIS HELPFUL &nbsp; üëè</b><br><br><b style=\"font-size: 22px; color: darkorange\">PLEASE UPVOTE!</b><br><br>This was a lot of work for me and while it may seem silly, it makes me feel appreciated when others like my work. üòÖ\n</div></center>\n\n<hr>","metadata":{"papermill":{"duration":0.013585,"end_time":"2024-02-10T16:12:14.748599","exception":false,"start_time":"2024-02-10T16:12:14.735014","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<p id=\"toc\"></p>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: #f4b37a; background-color: #ffffff;\">\n    TABLE OF CONTENTS\n</h1>\n\n<hr>\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; background-color: #ffffff;\"><a href=\"#introduction\" style=\"text-decoration: none; color: #EB7550;\">1&nbsp;&nbsp;&nbsp;&nbsp;INTRODUCTION & JUSTIFICATION</a></h3>\n\n<hr>\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; background-color: #ffffff;\"><a href=\"#background_information\" style=\"text-decoration: none; color: #EB7550;\">2&nbsp;&nbsp;&nbsp;&nbsp;BACKGROUND INFORMATION</a></h3>\n\n<hr>\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; background-color: #ffffff;\"><a href=\"#imports\" style=\"text-decoration: none; color: #EB7550;\">3&nbsp;&nbsp;&nbsp;&nbsp;IMPORTS</a></h3>\n\n<hr>\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; background-color: #ffffff;\"><a href=\"#setup\" style=\"text-decoration: none; color: #EB7550;\">4&nbsp;&nbsp;&nbsp;&nbsp;SETUP & HELPER FUNCTIONS</a></h3>\n\n<hr>\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; background-color: #ffffff;\"><a href=\"#eda\" style=\"text-decoration: none; color: #EB7550;\">5&nbsp;&nbsp;&nbsp;&nbsp;EXPLORATORY DATA ANALYSIS</a></h3>\n\n<hr>\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; background-color: #ffffff;\"><a href=\"#baseline\" style=\"text-decoration: none; color: #EB7550;\">6&nbsp;&nbsp;&nbsp;&nbsp;BASELINE</a></h3>\n\n<hr>\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; background-color: #ffffff;\"><a href=\"#next_steps\" style=\"text-decoration: none; color: #EB7550;\">7&nbsp;&nbsp;&nbsp;&nbsp;NEXT STEPS</a></h3>\n\n<hr>\n\n<br>","metadata":{"papermill":{"duration":0.012817,"end_time":"2024-02-10T16:12:14.774783","exception":false,"start_time":"2024-02-10T16:12:14.761966","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<br>\n\n<a id=\"introduction\"></a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: #f4b37a;\" id=\"introduction\">1&nbsp;&nbsp;INTRODUCTION & JUSTIFICATION&nbsp;&nbsp;&nbsp;&nbsp;<a style=\"text-decoration: none; color: #f8d2b0;\" href=\"#toc\">&#10514;</a></h1>\n\n<br>","metadata":{"papermill":{"duration":0.012871,"end_time":"2024-02-10T16:12:14.800882","exception":false,"start_time":"2024-02-10T16:12:14.788011","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">1.1 <b>WHAT</b> IS THIS?</h3>\n<hr>\n\n<ul>\n    <li style=\"font-family: Verdana;\">This notebook will follow the authors learning path and highlight relevant terms, information, and useful content about the competition.</li>\n    <li>This notebook will conduct an <b>E</b>xploratory <b>D</b>ata <b>A</b>nalysis for the competition.</li>\n    <li>This notebook will propose an open-source baseline solution.</li>\n</ul>\n\n<br>","metadata":{"papermill":{"duration":0.012837,"end_time":"2024-02-10T16:12:14.827357","exception":false,"start_time":"2024-02-10T16:12:14.81452","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">1.2 <b>WHY</b> IS THIS?</h3>\n<hr>\n\n<ul>\n    <li>Writing and sharing my learning path and the resulting exploratory data analysis can help improve my own understanding of the competition and the data.</li>\n    <li>Sharing my work may help others who are interested in the competition (or the data). This help may take the form of:\n        <ul>\n            <li>Better understanding the problem and potential common solutions (incl. my baseline).</li>\n            <li>Better understanding of the provided dataset.</li>\n            <li>Better understanding of the background information and research.</li>\n            <li>Better ability to hypothesize new solutions.</li>\n        </ul>\n    </li>\n    <li>Exploratory data analysis is a critical step in any data science project. Sharing my EDA might help others in the competition.</li>\n    <li>Writing and sharing my work is often a fun and rewarding experience! It not only allows me to explore and try different techniques, ideas, and visualizations but also encourages and supports other learners and participants.</li>\n</ul>\n\n<br>","metadata":{"papermill":{"duration":0.012759,"end_time":"2024-02-10T16:12:14.853408","exception":false,"start_time":"2024-02-10T16:12:14.840649","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">1.3 <b>WHO</b> IS THIS FOR?</h3>\n<hr>\n\n<ul>\n    <li>The primary purpose of this notebook is to educate <b>MYSELF</b>, however, my review/learning might be beneficial to others:\n        <ul>\n            <li>Other Kagglers (aka. current and future competition participants).</li>\n            <li>Anyone interested in learning more about sign language recognition and its potential applications.</li>\n            <li>Educators, students, or researchers who want to gain hands-on experience working with real-world data and building machine learning models and want to follow along with something relatively straightforward.</li>\n            <li>Those who want to learn how to use specific tools (competition specific and data science) and libraries such as TensorFlow Lite, MediaPipe, pandas, numpy, etc.</li>\n        </ul>\n    </li>\n</ul>\n\n<br>","metadata":{"papermill":{"duration":0.012802,"end_time":"2024-02-10T16:12:14.879847","exception":false,"start_time":"2024-02-10T16:12:14.867045","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">1.4 <b>HOW</b> WILL THIS WORK?</h3>\n<hr>\n\n<p>I'm going to assemble some markdown cells (like this one) at the beginning of the notebook to go over some concepts/details/etc.</p>\n\n<p>Following this, I will attempt to walk through the data and understand it better prior to composing a baseline solution.</p>\n\n<br>","metadata":{"papermill":{"duration":0.012822,"end_time":"2024-02-10T16:12:14.905955","exception":false,"start_time":"2024-02-10T16:12:14.893133","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<a id=\"background_information\"></a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: #f4b37a;\" id=\"background_information\">2&nbsp;&nbsp;BACKGROUND INFORMATION&nbsp;&nbsp;&nbsp;&nbsp;<a style=\"text-decoration: none; color: #f8d2b0;\" href=\"#toc\">&#10514;</a></h1>\n\n<br>","metadata":{"papermill":{"duration":0.013057,"end_time":"2024-02-10T16:12:14.932855","exception":false,"start_time":"2024-02-10T16:12:14.919798","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">2.1 <b>OVERVIEW</b></h3>\n<hr>\n\n<div style=\"font-family: Verdana !important;\">\n    <br>\n    <b style=\"text-decoration: underline; font-family: Verdana; font-size: 15px; text-transform: uppercase; letter-spacing: 2px;\">PRIMARY TASK DESCRIPTION</b>\n    <br>\n    <br>\n    <div style=\"font-family: Verdana !important;\">\n        The goal of this competition is to <b>develop a model that detects personally identifiable information (PII)</b> in student writing.\n        <br>\n        <br>\n        Submissions are evaluated on micro <b>F<sub>Œ≤</sub></b>, which is a classification metric that assigns value to recall and precision. \n        The value of <b>Œ≤</b> is set to <b>5</b>, indicating that recall is weighted 5 times more heavily than precision.\n        <br>\n        <br>\n        The formula for calculating <b>F<sub>Œ≤</sub></b> is given by:\n        <br>\n        <br>\n        $F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{precision \\cdot recall}{(\\beta^2 \\cdot precision) + recall}$\n        <br>\n        <sub>Where <b>Œ≤ = 5</b>, emphasizing the importance of recall in this evaluation.</sub>\n    </div>\n</div>\n\n<br>\n\n<div style=\"font-family: Verdana !important;\">\n    <br>\n    <b style=\"text-decoration: underline; font-family: Verdana; font-size: 15px; text-transform: uppercase; letter-spacing: 2px;\">ELI5 TASK DESCRIPTION</b>\n    <br>\n    <sup><b>ChatGPT was used to help generate this.</b></sup>\n    <br>\n    <br>\n    <div style=\"font-family: Verdana;\">\n        In a <span style=\"color: green;\"><b>magical kingdom</b></span>, there's a quest to train <span style=\"color: blue;\"><b>fairies</b></span> (<b>models</b>) to find hidden <span style=\"color: red;\"><b>spells</b></span> (<b>PII</b>) in magic <span style=\"color: orange;\"><b>books</b></span> (<b>student writings</b>).\n        <br>\n        <b>These spells are secret words that protect people's treasures.</b>\n        <br>\n        <br>\n        <p>The most important task for these fairies is <span style=\"color: magenta;\"><b>not to miss any spells</b></span> (<b>high recall</b>), because leaving even one spell unfound could put a treasure at risk. \n        <br>\n        It's like playing hide and seek where it's crucial to find everyone hiding, even if it means <span style=\"color: gray;\"><b>occasionally thinking someone is hiding when they're not</b></span> (<b>precision</b>).</p>\n        <b>The goal is to ensure no treasure is ever exposed, making the kingdom's wisdom safe to share with everyone.</b>\n    </div>\n</div>\n\n<br>\n\n<div style=\"font-family: Verdana !important;\">\n    <br>\n    <b style=\"text-decoration: underline; font-family: Verdana; font-size: 15px; text-transform: uppercase; letter-spacing: 2px;\">COMPETITION HOST(S)/CONTRIBUTOR(S)</b>\n    <br>\n    <ul>\n        <li><b>Vanderbilt University:</b> A private research university in Nashville, Tennessee, known for its extensive range of programs and dedication to cross-disciplinary research. It serves as the competition host.</li>\n        <li><b>The Learning Agency Lab:</b> An Arizona-based nonprofit partnered with Vanderbilt for the competition, focused on developing tools and programs for learning science and social good.</li>\n        <li><b>The National AI Institute for Adult Learning and Online Education (AI-ALOE):</b> Provided support for the competition, emphasizing the collaboration to use AI for educational advancements.</li>\n    </ul>\n</div>\n\n<br>\n\n<div style=\"font-family: Verdana !important;\">\n    <b style=\"text-decoration: underline; font-family: Verdana; font-size: 15px; text-transform: uppercase; letter-spacing: 2px;\">HOST TASK DESCRIPTION</b>\n    <br>\n    <br>\n    <div>\n        In today‚Äôs era of abundant educational data from sources such as ed tech, online learning, and research, widespread PII is a key challenge. \n        PII‚Äôs presence is a barrier to analyze and create open datasets that advance education because releasing the data publicly puts students at risk. \n        To reduce these risks, it‚Äôs crucial to screen and cleanse educational data for PII before public release, which data science could streamline.\n    </div>\n    <br>\n    <div>\n    Manually reviewing the entire dataset for PII is currently the most reliable screening method, but this results in significant costs and restricts the scalability of educational datasets. \n        While techniques for automatic PII detection that rely on named entity recognition (NER) exist, these work best for PII that share common formatting such as emails and phone numbers. \n        PII detection systems struggle to correctly label names and distinguish between names that are sensitive (e.g., a student's name) and those that are not (e.g., a cited author).\n    </div>\n    <br>\n    <div>\n        Your work in creating reliable automated techniques to detect PII will lead to more high-quality public educational datasets.\n        Researchers can then tap into the potential of this previously unavailable data to develop effective tools and interventions that benefit both teachers and students.\n    </div>\n</div>\n\n<br>\n\n<div style=\"font-family: Verdana !important;\">\n    <b style=\"text-decoration: underline; font-family: Verdana; font-size: 15px; text-transform: uppercase; letter-spacing: 2px;\">EXAMPLES OF PII IN ESSAYS</b>\n    <br>\n    <br>\n    <b><sub>Below is an example from our train dataset... notice how the email is missed... clearly the dataset isn't perfect.</sub></b>\n    <br>\n    <br>\n    <img src=\"https://github.com/darien-schettler/asset-hosting/blob/main/example_displacy.png?raw=true\">\n    <br>\n    <div>\n        <b>I may make a markdown table and put common examples here... later</b>\n    </div>\n</div>","metadata":{"papermill":{"duration":0.013355,"end_time":"2024-02-10T16:12:14.95994","exception":false,"start_time":"2024-02-10T16:12:14.946585","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">2.2 <b>DATASET INFORMATION</b></h3>\n\n<hr>\n\n<br><b style=\"text-decoration: underline; font-family: Verdana; font-size: 15px; text-transform: uppercase; letter-spacing: 2px;\">HIGH LEVEL DATA SUMMARY</b>\n\nThis dataset is designed to support the development of models that can detect and classify personally identifiable information (PII) in essays written by students. The automated detection and anonymization of PII in educational data will significantly reduce the costs associated with making educational datasets available. This, in turn, can accelerate research in learning sciences and aid in the creation of new educational technologies.\n\n<br>\n\n<b>DATA COMPOSITION</b>\n- **Essays:** Approximately 22,000 essays written by students, each identified by a unique `document` integer ID.\n- **Tokens:** The essays have been tokenized using the SpaCy English tokenizer, with each token and its trailing whitespace status provided.\n- **PII Annotations:** Annotations in BIO (Beginning, Inner, Outer) format, indicating the type of PII (e.g., `B-NAME_STUDENT`, `I-EMAIL`) found within the tokens.\n\n<br>\n\n<b>DATA FORMAT AND FILES</b>\n- **JSON Data Files:** `train.json` and `test.json` containing the essays' full text, tokens, whitespace information, and PII annotations for the training data.\n- **PII Types:** The dataset includes labels for seven types of PII such as `NAME_STUDENT`, `EMAIL`, `USERNAME`, `ID_NUM`, `PHONE_NUM`, `URL_PERSONAL`, and `STREET_ADDRESS`.\n\n<br>\n\n<b>UNIQUE ASPECTS OF THE DATASET</b>\n- **Surrogate PII Identifiers:** To protect student privacy, original PII has been replaced with surrogate identifiers of the same type through a partially automated process.\n- **External Data Encouraged:** Competitors are encouraged to augment their training data with publicly available datasets due to the majority of essays being reserved for the test set.\n\n<br>\n\n<b>CHALLENGES AND OPPORTUNITIES</b>\n- **Data Cleanliness:** The critical challenge of accurately detecting and anonymizing PII in student essays, however, there appears to be missing labels and some sparsity with respect to certain conditional categorization of PII. Additional data WILL be required.\n\n<br>\n\n<br><b style=\"text-decoration: underline; font-family: Verdana; font-size: 15px; text-transform: uppercase; letter-spacing: 2px;\">DATA FILE DESCRIPTIONS</b>\n\n<b><code>train.json</code> and <code>test.json</code>:</b>\n* Contain detailed information about each essay, including:\n    - <b><code>document</code> (int):</b> An integer ID of the essay.\n    - <b><code>full_text</code> (string):</b> A UTF-8 representation of the essay.\n    - <b><code>tokens</code> (list):</b> A string representation of each token.\n    - <b><code>trailing_whitespace</code> (list):</b> Indicates whether each token is followed by whitespace (boolean).\n    - <b><code>labels</code> (list):</b> [Training data only] A token label in BIO format indicating the type of PII.\n\n<br>\n\n<br><b style=\"text-decoration: underline; font-family: Verdana; font-size: 15px; text-transform: uppercase; letter-spacing: 2px;\">POST-EDA DATA OBSERVATIONS</b>\n\nTBD\n\n<br>\n","metadata":{"papermill":{"duration":0.012953,"end_time":"2024-02-10T16:12:14.986181","exception":false,"start_time":"2024-02-10T16:12:14.973228","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">2.3 <b>EVALUATION INFORMATION</b></h3>\n<hr>\n\nSubmissions are judged based on a metric that prioritizes accurately identifying PII over avoiding false alarms. Participants need to label each piece of text in the test set that contains PII, excluding any text that doesn't contain PII (marked as `O`).\n\nThe metric chosen for this task is <b>Micro F<sub>Œ≤</sub></b> with <b>Œ≤=5</b>, meaning recall is weighted five times more heavily than precision.\n\n<br><b style=\"text-decoration: underline; font-family: Verdana; font-size: 15px; text-transform: uppercase; letter-spacing: 2px;\">BASIC EXPLANATION OF THE METRIC</b>\n\n<b>Micro F<sub>Œ≤</sub></b> is a classification metric used to evaluate the balance between precision (how many selected items are relevant) and recall (how many relevant items are selected). The Œ≤ parameter adjusts the importance of recall relative to precision. \n\n* In our case, <b>Œ≤=5</b> emphasizes recall significantly more than precision. This means:\n    - It's more important for our models to correctly identify all instances of PII, even if it results in some false positives.\n\nThis metric is particularly suitable for situations where missing a true positive (failing to identify PII) is more detrimental than incorrectly labeling non-PII data as PII.\n\n<br>\n\n---\n\n<br><b style=\"text-decoration: underline; font-family: Verdana; font-size: 15px; text-transform: uppercase; letter-spacing: 2px;\">ELI5 EXPLANATION OF THE METRIC</b>\n\nImagine you're playing a game where you need to find hidden treasures (PII) in a large field (the dataset). \n\n* **Precision** is about how often your found treasures are actually treasures and not just rocks. \n* **Recall** is about how good you are at finding all the treasures in the field.\n\nNow, with <b>Micro F<sub>Œ≤</sub></b> and <b>Œ≤=5</b>, it's like saying finding all the treasures (even if you pick up some rocks thinking they're treasures) is 5 times more important than just being sure about each pick being a treasure.\n\nThis means in our competition, it's crucial to identify and label all possible PII, prioritizing not missing any over occasionally mislabeling non-PII as PII.\n\n<br>\n\n---\n\n<br><b style=\"text-decoration: underline; font-family: Verdana; font-size: 15px; text-transform: uppercase; letter-spacing: 2px;\">EXPLANATION OF THE METRIC WITH RESPECT TO THIS COMPETITION</b>\n\nIn the context of this competition, where the goal is to detect PII in student essays:\n\n* **The Reference Distribution**: The true labels of whether each token in the essays is a type of PII or not.\n* **Our Model's Distribution**: The predictions made by our model about each token being a PII or not.\n\nThe <b>Micro F<sub>Œ≤</sub></b> metric evaluates how well our model identifies PII across all essays. A high score means our model is excellent at catching PII (high recall) while maintaining a reasonable level of accuracy (precision), though with a strong emphasis on recall due to the Œ≤ value of 5.\n\n* Our main objective is to minimize the chances of missing any PII, given its importance over mistakenly identifying non-PII as PII.\n\n<br>\n\n<b>NOTE:</b> The challenge lies not only in accurately identifying clear instances of PII but also in handling ambiguous cases where the distinction between PII and non-PII isn't clear-cut (you can see the impact of this in the training dataset with missing labels), reflecting the real-world complexity of PII detection in text data.\n\n<br>\n\n---\n","metadata":{"papermill":{"duration":0.012825,"end_time":"2024-02-10T16:12:15.012095","exception":false,"start_time":"2024-02-10T16:12:14.99927","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">2.4 <b>COMPETITION IMPACT INFORMATION</b></h3>\n<hr>\n\n<br>\n\n> \"Your work in creating reliable automated techniques to detect PII will lead to more high-quality public educational datasets. Researchers can then tap into the potential of this previously unavailable data to develop effective tools and interventions that benefit both teachers and students.\"","metadata":{"papermill":{"duration":0.012863,"end_time":"2024-02-10T16:12:15.038384","exception":false,"start_time":"2024-02-10T16:12:15.025521","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<a id=\"imports\"></a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: #f4b37a;\" id=\"imports\">3&nbsp;&nbsp;IMPORTS&nbsp;&nbsp;&nbsp;&nbsp;<a style=\"text-decoration: none; color: #f8d2b0;\" href=\"#toc\">&#10514;</a></h1>\n\n<br>","metadata":{"papermill":{"duration":0.012906,"end_time":"2024-02-10T16:12:15.064587","exception":false,"start_time":"2024-02-10T16:12:15.051681","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(\"\\n... PIP INSTALLS STARTING ...\\n\")\nprint(\"\\n... PIP INSTALLS COMPLETE ...\\n\")\n\nprint(\"\\n... IMPORTS STARTING ...\\n\")\nprint(\"\\n\\tVERSION INFORMATION\")\n\n# Competition Imports\nimport spacy\nfrom spacy import displacy\nfrom spacy.tokens import Doc, Span\n\n# Keras/TF Imports\nimport tensorflow as tf; print(f\"\\t\\t- TENSORFLOW VERSION: {tf.__version__}\")\nimport pandas as pd; pd.options.mode.chained_assignment = None; pd.set_option('display.max_columns', None);\nimport numpy as np; print(f\"\\t\\t‚Äì NUMPY VERSION: {np.__version__}\");\nimport sklearn; print(f\"\\t\\t‚Äì SKLEARN VERSION: {sklearn.__version__}\");\n\n# ML Imports\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.manifold import TSNE\n\n# Built-In Imports (mostly don't worry about these)\nfrom typing import Iterable, Any, Callable\nfrom kaggle_datasets import KaggleDatasets\nfrom dataclasses import dataclass\nfrom collections import Counter\nfrom datetime import datetime\nfrom zipfile import ZipFile\nfrom glob import glob\nimport Levenshtein\nimport warnings\nimport requests\nimport textwrap\nimport hashlib\nimport imageio\nimport IPython\nimport urllib\nimport zipfile\nimport pickle\nimport random\nimport shutil\nimport string\nimport json\nimport math\nimport time\nimport gzip\nimport ast\nimport sys\nimport io\nimport gc\nimport re\nimport os\n\n# Visualization Imports (overkill)\nfrom matplotlib.animation import FuncAnimation\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib.patches import Rectangle\nimport matplotlib.patches as patches\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nfrom IPython.display import HTML\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom tqdm.notebook import tqdm; tqdm.pandas();\nimport plotly.express as px\nimport tifffile as tif\nimport seaborn as sns\nfrom PIL import Image, ImageEnhance; Image.MAX_IMAGE_PIXELS = 5_000_000_000;\nimport matplotlib; print(f\"\\t\\t‚Äì MATPLOTLIB VERSION: {matplotlib.__version__}\");\nfrom matplotlib import animation, rc; rc('animation', html='jshtml')\nimport plotly\nimport PIL\nimport cv2\n\nimport plotly.io as pio\nprint(pio.renderers)\n\ndef seed_it_all(seed=7):\n    \"\"\" Attempt to be Reproducible \"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \nseed_it_all()\n\nprint(\"\\n\\n... IMPORTS COMPLETE ...\\n\")","metadata":{"papermill":{"duration":99.12323,"end_time":"2024-02-10T16:13:54.201136","exception":false,"start_time":"2024-02-10T16:12:15.077906","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-17T18:45:54.74782Z","iopub.execute_input":"2024-02-17T18:45:54.748325Z","iopub.status.idle":"2024-02-17T18:46:18.566982Z","shell.execute_reply.started":"2024-02-17T18:45:54.748294Z","shell.execute_reply":"2024-02-17T18:46:18.566083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"setup\"></a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: #f4b37a;\" id=\"setup\">4&nbsp;&nbsp;SETUP & HELPER FUNCTIONS&nbsp;&nbsp;&nbsp;&nbsp;<a style=\"text-decoration: none; color: #f8d2b0;\" href=\"#toc\">&#10514;</a></h1>\n\n<br>","metadata":{"papermill":{"duration":0.014992,"end_time":"2024-02-10T16:13:54.231423","exception":false,"start_time":"2024-02-10T16:13:54.216431","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">4.0 FUNCTIONS FROM <b>OTHER KAGGLERS</b> ü©µ</h3>\n<hr><br>\n\nTBD\n\n<br>","metadata":{"papermill":{"duration":0.016218,"end_time":"2024-02-10T16:13:54.263301","exception":false,"start_time":"2024-02-10T16:13:54.247083","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">4.1 <b>HELPER</b> FUNCTIONS</h3>\n<hr><br>\n\nThese are some functions I carry around with me that I find commonly helpful.","metadata":{"papermill":{"duration":0.013775,"end_time":"2024-02-10T16:13:54.292196","exception":false,"start_time":"2024-02-10T16:13:54.278421","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def flatten_l_o_l(nested_list):\n    \"\"\" Flatten a list of lists into a single list.\n\n    Args:\n        nested_list (Iterable): \n            ‚Äì A list of lists (or iterables) to be flattened.\n\n    Returns:\n        A flattened list containing all items from the input list of lists.\n    \"\"\"\n    return [item for sublist in nested_list for item in sublist]\n\n\ndef print_ln(symbol=\"-\", line_len=110, newline_before=False, newline_after=False):\n    \"\"\" Print a horizontal line of a specified length and symbol.\n\n    Args:\n        symbol (str, optional): \n            ‚Äì The symbol to use for the horizontal line\n        line_len (int, optional): \n            ‚Äì The length of the horizontal line in characters\n        newline_before (bool, optional): \n            ‚Äì Whether to print a newline character before the line\n        newline_after (bool, optional): \n            ‚Äì Whether to print a newline character after the line\n            \n    Returns:\n        None; A divider with pre/post new-lines (optional) is printed\n    \"\"\"\n    if newline_before: print();\n    print(symbol * line_len)\n    if newline_after: print();\n        \ndef display_hr(newline_before=False, newline_after=False):\n    \"\"\" Renders a HTML <hr>\n\n    Args:\n        newline_before (bool, optional): \n            ‚Äì Whether to print a newline character before the line\n        newline_after (bool, optional): \n            ‚Äì Whether to print a newline character after the line\n            \n    Returns:\n        None; A divider with pre/post new-lines (optional) is printed\n    \"\"\"\n    if newline_before: print();\n    display(HTML(\"<hr>\"))\n    if newline_after: print();\n\n\ndef wrap_text(text, width=88):\n    \"\"\"Wrap text to a specified width.\n\n    Args:\n        text (str): \n            - The text to wrap.\n        width (int): \n            - The maximum width of a line. Default is 88.\n\n    Returns:\n        str: The wrapped text.\n    \"\"\"\n    return textwrap.fill(text, width)\n\n\ndef wrap_text_by_paragraphs(text, width=88):\n    \"\"\"Wrap text by paragraphs to a specified width.\n\n    Args:\n        text (str): \n            - The text containing multiple paragraphs to wrap.\n        width (int): \n            - The maximum width of a line. Default is 88.\n\n    Returns:\n        str: The wrapped text with preserved paragraph separation.\n    \"\"\"\n    paragraphs = text.split('\\n')  # Assuming paragraphs are separated by newlines\n    wrapped_paragraphs = [textwrap.fill(paragraph, width) for paragraph in paragraphs]\n    return '\\n\\n'.join(wrapped_paragraphs)\n\n\ndef get_spacy_nlp_model(spacy_nlp_name=\"en_core_web_sm\", spacy_nlp_path=None):\n    _spacy_nlp = spacy_nlp_path or spacy_nlp_name\n    return spacy.load(_spacy_nlp)\n\n\n# def calculate_token_positions(full_text: str, tokens: list[str], trailing_spaces: list[bool]) -> list[tuple[int, int]]:\n#     \"\"\"\n#     Calculate the start and end positions of tokens in the full text.\n\n#     Args:\n#         full_text (str): The full text of the document.\n#         tokens (List[str]): A list of string representations of each token.\n#         trailing_spaces (List[bool]): A list indicating whether each token is followed by whitespace.\n\n#     Returns:\n#         List[Tuple[int, int]]: A list of tuples, each representing the start and end positions of a token.\n#     \"\"\"\n#     positions = []\n#     start = 0\n#     for token, has_space in zip(tokens, trailing_spaces):\n#         end = start + len(token)\n#         positions.append((start, end))\n#         start = end + (1 if has_space else 0)\n#     return positions\n\n# def bio_to_spacy_entity_list(full_text: str, tokens: list[str], trailing_whitespace: list[bool], labels: list[str], **kwargs) -> list[tuple[int, int, str]]:\n#     \"\"\"\n#     Convert tokens and BIO labels into spaCy entity spans, adjusted to work with string tokens and their positions.\n\n#     Args:\n#         full_text (str): The full text of the document.\n#         tokens (List[str]): A list of string representations of each token.\n#         trailing_whitespace (List[bool]): A list indicating whether each token is followed by whitespace.\n#         labels (List[str]): A list of BIO labels corresponding to each token.\n\n#     Returns:\n#         List[Tuple[int, int, str]]: A list of tuples, each representing an entity span for spaCy.\n#     \"\"\"\n#     token_positions = calculate_token_positions(full_text, tokens, trailing_whitespace)\n#     entities = []\n#     current_label = None\n#     for (start, end), label in zip(token_positions, labels):\n#         if label.startswith('B-'):\n#             if current_label:\n#                 entities.append(current_label)\n#             current_label = (start, end, label[2:])\n#         elif label.startswith('I-') and current_label:\n#             current_label = (current_label[0], end, current_label[2])\n#         else:\n#             if current_label:\n#                 entities.append(current_label)\n#                 current_label = None\n#     if current_label:\n#         entities.append(current_label)\n#     return entities\n\ndef bio_to_spacy_entities(doc, labels):\n    \"\"\"Convert BIO-tagged labels into spaCy entity spans.\n\n    Args:\n        doc (Doc): A spaCy Doc object containing the tokenized text.\n        labels (List[str]): A list of BIO labels corresponding to each token in the Doc.\n\n    Returns:\n        List[Span]: A list of spaCy Span objects representing the entities.\n    \"\"\"\n    entities = []\n    start = None  # Track start index of the entity\n    for i, (token, label) in enumerate(zip(doc, labels)):\n        if label.startswith('B-'):\n            start = i\n        elif label.startswith('I-') and start is not None:\n            continue\n        elif start is not None:\n            # End of the entity\n            entities.append(Span(doc, start, i, label=labels[start][2:]))\n            start = None\n        if label.startswith('B-') and i == len(doc) - 1:\n            # Handle case where an entity is at the end of the text\n            entities.append(Span(doc, start, i+1, label=label[2:]))\n    if start is not None:\n        # Ensure any final entity is added\n        entities.append(Span(doc, start, len(doc), label=labels[start][2:]))\n    return entities\n\ndef count_tags(entity_list, competition_labels=\"default\"):\n    \"\"\"Count the occurrences of BIO-tagged entities within a list for specified competition labels.\n\n    Args:\n        entity_list (list): \n            - A list of entities with BIO tagging.\n        competition_labels (list, optional): \n            - A list of labels to consider for counting. \n\n    Returns:\n        dict: A dictionary with counts of each tag for the competition labels and 'O'.\n\n    \"\"\"\n\n    if not isinstance(competition_labels, list):\n        competition_labels = COMPETITION_LABELS\n\n    # Initialize a dictionary to hold counts for all possible tags\n    counts = {f'{tag}{lbl}': 0 for lbl in competition_labels for tag in ['B-', 'I-']}\n    counts['O'] = 0  # 'O' is for tokens outside of any named entity\n\n    # Count occurrences using Counter\n    counter = Counter(entity_list)\n\n    # Update counts for each tag found in the entity list\n    for tag, count in counter.items():\n        if tag in counts:\n            counts[tag] += count\n        else:\n            # Split tag into prefix and label if it's not 'O'\n            prefix, lbl = tag.split('-', 1) if '-' in tag else ('O', 'O')\n            if lbl in competition_labels:\n                counts[tag] = count\n\n    return counts\n\n\ndef add_tag_count_columns(df, column_name='labels', competition_labels=\"default\"):\n    \"\"\"Adds columns to the DataFrame for counts of each tag based on the entities in a specified column.\n\n    Args:\n        df (pandas.DataFrame): \n            - The DataFrame containing a column with tagged entities.\n        column_name (str, optional): \n            - The name of the column with tagged entities. Defaults to 'labels'.\n        competition_labels (list or str, optional): \n            - Labels to count within the entities. \n\n    Returns:\n        pandas.DataFrame: \n            - A new DataFrame with original data and added columns for tag counts.\n        \n    Example Usage:\n        >>> df_enriched = add_tag_count_columns(df, 'labels', COMPETITION_LABELS)\n    \"\"\"\n    # Apply count_tags to each row in the specified column and convert to DataFrame\n    tag_counts_df = pd.DataFrame(df[column_name].apply(count_tags, competition_labels=competition_labels).tolist())\n    \n    # Concatenate the original DataFrame with the new columns\n    return pd.concat([df, tag_counts_df], axis=1)\n\ndef add_pii_count(df, column_name=\"labels\"):\n    \"\"\"Get example-wise PII counts (total and unique).\n    \n    Args:\n        df (pandas.DataFrame): \n            - The DataFrame containing a column with tagged entities.\n        column_name (str, optional): \n            - The name of the column with tagged entities. Defaults to 'labels'.\n            \n    Returns:\n        The updated pandas.DataFrame\n    \"\"\"\n    \n    # Count the non-'O' labels\n    df[\"total_pii_count\"] = df[column_name].apply(lambda lbl_list: sum([1 if lbl!=\"O\" else 0 for lbl in lbl_list]))\n    df[\"unique_pii_count\"] = df[column_name].apply(lambda lbl_list: sum([1 if lbl!=\"O\" else 0 for lbl in set(lbl_list)]))\n    return df\n\ndef second_most_common(iterable: Iterable) -> Any | None:\n    \"\"\"Returns the second most common element in the given iterable.\n    \n    If the iterable doesn't have enough unique elements, returns None.\n\n    Args:\n    - iterable (Iterable): An iterable collection of elements.\n\n    Returns:\n        - Any | None: The second most common element, or None if not applicable.\n    \"\"\"\n    # Count the elements in the iterable\n    counts = Counter(iterable)\n    \n    # Sort the elements by frequency in descending order and get the keys\n    most_common_keys = [key for key, _ in counts.most_common()]\n    \n    # Return the second most common key if it exists, else None\n    return most_common_keys[1] if len(most_common_keys) > 1 else None","metadata":{"papermill":{"duration":0.035679,"end_time":"2024-02-10T16:13:54.3447","exception":false,"start_time":"2024-02-10T16:13:54.309021","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-17T18:46:18.568807Z","iopub.execute_input":"2024-02-17T18:46:18.569333Z","iopub.status.idle":"2024-02-17T18:46:18.602966Z","shell.execute_reply.started":"2024-02-17T18:46:18.569303Z","shell.execute_reply":"2024-02-17T18:46:18.601577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">4.2 <b>LOAD</b> THE DATA</h3>\n<hr><br>\n\nWe also define path information and other constants that are helpful in establishing early.\n\n<br>","metadata":{"papermill":{"duration":0.014677,"end_time":"2024-02-10T16:13:54.37367","exception":false,"start_time":"2024-02-10T16:13:54.358993","status":"completed"},"tags":[]}},{"cell_type":"code","source":"COMPETITION_LABELS = [\n    \"NAME_STUDENT\", \n    \"EMAIL\", \n    \"USERNAME\", \n    \"ID_NUM\", \n    \"PHONE_NUM\", \n    \"URL_PERSONAL\", \n    \"STREET_ADDRESS\"\n]\n\n# ROOT PATHS\nWORKING_DIR = \"/kaggle/working\"\nINPUT_DIR = \"/kaggle/input\"\nCOMPETITION_DIR = os.path.join(INPUT_DIR, \"pii-detection-removal-from-educational-data\")\n\n# COMPETITION FILE PATHS\nSS_CSV_PATH = os.path.join(COMPETITION_DIR, \"sample_submission.csv\")\nTRAIN_JSON_PATH = os.path.join(COMPETITION_DIR, \"train.json\")\nTEST_JSON_PATH = os.path.join(COMPETITION_DIR, \"test.json\")\n\n# DEFINE COMPETITION DATAFRAMES\nss_df = pd.read_csv(SS_CSV_PATH)\ntrain_df = add_tag_count_columns(add_pii_count(pd.read_json(TRAIN_JSON_PATH)))\ntest_df = pd.read_json(TEST_JSON_PATH)\n\nspacy_nlp = get_spacy_nlp_model()\n\n# Visualize the entities\nCUSTOM_LABEL_COLORS = {\n    \"ORG\": \"#7aecec\",\n    \"PRODUCT\": \"#bfeeb7\",\n    \"GPE\": \"#feca74\",\n    \"LOC\": \"#ff9561\",\n    \"PERSON\": \"#aa9cfc\",\n    \"NORP\": \"#c887fb\",\n    \"FAC\": \"#9cc9cc\",\n    \"EVENT\": \"#ffeb80\",\n    \"LAW\": \"#ff8197\",\n    \"LANGUAGE\": \"#ff8197\",\n    \"WORK_OF_ART\": \"#f0d0ff\",\n    \"DATE\": \"#bfe1d9\",\n    \"TIME\": \"#bfe1d9\",\n    \"MONEY\": \"#e4e7d2\",\n    \"QUANTITY\": \"#e4e7d2\",\n    \"ORDINAL\": \"#e4e7d2\",\n    \"CARDINAL\": \"#e4e7d2\",\n    \"PERCENT\": \"#e4e7d2\",\n    # Custom entities for PII\n    \"NAME_STUDENT\": \"#4287f5\",  # Bright blue\n    \"EMAIL\": \"#fa8334\",  # Bright orange\n    \"USERNAME\": \"#34fafa\",  # Cyan\n    \"ID_NUM\": \"#f534fa\",  # Magenta\n    \"PHONE_NUM\": \"#83fa34\",  # Lime green\n    \"URL_PERSONAL\": \"#3456fa\",  # Royal blue\n    \"STREET_ADDRESS\": \"#fa3434\",  # Bright red\n}\nCOMPETITION_DISPLACY_OPTIONS = {\n    \"ents\": COMPETITION_LABELS,\n    \"colors\": {k:v for k,v in CUSTOM_LABEL_COLORS.items() if k in COMPETITION_LABELS}\n}\n\n# CORE OBJECTS\nprint(\"\\n... SAMPLE SUBMISSION DATAFRAME ...\\n\\n\")\ndisplay_hr(newline_before=True, newline_after=True)\ndisplay(ss_df)\ndisplay_hr(newline_before=True, newline_after=True)\n\nprint(\"\\n... TRAIN DATAFRAME ...\\n\\n\")\ndisplay(train_df.info())\ndisplay(train_df.describe())\ndisplay(train_df)\ndisplay_hr(newline_before=True, newline_after=True)\n\nprint(\"\\n... TEST DATAFRAME ...\\n\\n\")\ndisplay(test_df.info())\ndisplay(test_df.describe())\ndisplay(test_df)\ndisplay_hr(newline_before=True, newline_after=True)","metadata":{"papermill":{"duration":1.248043,"end_time":"2024-02-10T16:13:55.63625","exception":false,"start_time":"2024-02-10T16:13:54.388207","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-17T18:46:18.604593Z","iopub.execute_input":"2024-02-17T18:46:18.604911Z","iopub.status.idle":"2024-02-17T18:46:24.733548Z","shell.execute_reply.started":"2024-02-17T18:46:18.604884Z","shell.execute_reply":"2024-02-17T18:46:24.732335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"eda\"></a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: #f4b37a;\" id=\"eda\">5&nbsp;&nbsp;EXPLORATORY DATA ANALYSIS&nbsp;&nbsp;&nbsp;&nbsp;<a style=\"text-decoration: none; color: #77AAB0;\" href=\"#toc\">&#10514;</a></h1>\n\n<br>\n","metadata":{"papermill":{"duration":0.01959,"end_time":"2024-02-10T16:13:55.674102","exception":false,"start_time":"2024-02-10T16:13:55.654512","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:46:24.735943Z","iopub.execute_input":"2024-02-17T18:46:24.73627Z","iopub.status.idle":"2024-02-17T18:46:24.783445Z","shell.execute_reply.started":"2024-02-17T18:46:24.736244Z","shell.execute_reply":"2024-02-17T18:46:24.780038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">5.1 <b>PROVIDED</b> COLUMNS</h3>\n<hr><br>\n\n**COLUMN SPECIFIC INFORMATION**\n\n**`document`**\n- HOST PROVIDED INFO:\n    - **`document`** is a unique identifier for each essay. \n    - This ID represents a specific student's essay, encompassing all the textual content provided in response to the assignment prompt.\n- ADDITIONAL INFO:\n    - **Purpose**: Helps in tracking and analyzing essays individually, ensuring accurate association of PII annotations to the correct text.\n    - **Data Handling**: Crucial for managing data splits between training and test sets, and for associating external datasets when augmenting the training data.\n\n**`full_text`**\n- HOST PROVIDED INFO:\n    - **`full_text`** provides the entire content of a student's essay in UTF-8 format. It represents the student's response to the assignment prompt, encompassing their entire argument, analysis, or narrative.\n- ADDITIONAL INFO:\n    - **Purpose**: Serves as the primary source for extracting tokens and identifying PII. It allows for a holistic view of the essay's content, crucial for understanding context and detecting nuanced instances of PII.\n    - **Data Handling**: Essential for pre-processing steps like tokenization and for tasks requiring textual analysis at a broader scale than individual tokens or entities. \n    - **Contextual Analysis**: The full essay text is vital for models that leverage context to improve PII detection accuracy. Understanding the narrative or argumentative flow can aid in distinguishing between PII and similar non-PII text.\n\n**`tokens`**\n- HOST PROVIDED INFO:\n    - **`tokens`** are the segmented pieces of the essay text, tokenized using the SpaCy English tokenizer.\n- ADDITIONAL INFO:\n    - **Text Analysis**: Facilitates detailed linguistic and semantic analysis at the token level, essential for PII detection.\n    - **Model Input**: Serves as the input for machine learning models designed to identify and classify PII within the text.\n\n**`trailing_whitespace`**\n- HOST PROVIDED INFO:\n    - Indicates whether each token is followed by whitespace, aiding in reconstructing the full text from tokens.\n- ADDITIONAL INFO:\n    - **Formatting**: Important for maintaining the original text structure, especially when visualizing annotations or extracting text segments.\n\n**`labels`** [training data only]\n- HOST PROVIDED INFO:\n    - Provides BIO-format annotations for identifying types of PII in the essays.\n- ADDITIONAL INFO:\n    - **Model Training**: Essential for supervised learning tasks, allowing models to learn from accurately labeled examples of PII.\n    - **Evaluation and Validation**: Used to assess model performance in correctly identifying and classifying PII entities.\n\n---\n\n<br>\n\n**THINGS WE NEED TO EXPLORE...**\n\n- **Data Quality and Privacy**: \n    - Ensuring the surrogate PII identifiers maintain anonymity while being useful for training models.\n    - Assessing the consistency and accuracy of PII annotations across the dataset.\n- **Feature Engineering**: \n    - Exploring NLP techniques for enhancing model sensitivity to context, which is crucial for accurately identifying PII.\n    - Investigating the use of token-level and contextual embeddings (e.g., BERT, GPT) for improved PII detection.\n- **Machine Learning Approaches**: \n    - Evaluating different model architectures, such as CRF, LSTM, and Transformer-based models, for their effectiveness in PII detection.\n    - Sharing insights from successful models and approaches within the competition community for collaborative improvement.\n\n<br>\n","metadata":{"papermill":{"duration":0.017207,"end_time":"2024-02-10T16:13:55.777556","exception":false,"start_time":"2024-02-10T16:13:55.760349","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**`document`**\n* Unique [7 to 22687]","metadata":{}},{"cell_type":"code","source":"TEXT_TRUNC_MAX_CHARS = 1_000\nTEXT_WRAP_AT = 120\nTFIDF_MAX_FEATURES = 800\nN_DIMS = 2\n\n# Step 1: Vectorize Text\nvectorizer = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES)\nX = vectorizer.fit_transform(train_df.full_text.to_numpy())\nX_dense = np.asarray(X.todense())\n\n# Step 2: Apply PCA\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_dense)\npca = PCA(n_components=N_DIMS)\nX_pca = pca.fit_transform(X_scaled)\n\n# Step 3: Visualization\n_df = pd.DataFrame(X_pca, columns=['PCA1', 'PCA2', 'PCA3'][:N_DIMS])\n_df['document'] = train_df.document.to_list()    # for hover\n_df[\"full_text\"] = train_df.full_text.apply(lambda x: wrap_text(x[:TEXT_TRUNC_MAX_CHARS], TEXT_WRAP_AT).replace('\\n', '<br>')+\"<br> ... [TRUNC] ...\").to_list()\n\n# Use second_most_common to avoid \"O\" label\n#  - We also drop the prefix (BIO) to just focus on the PII labels themselves.\n_df[\"most_common_pii_detected\"] = train_df.labels.apply(\n    lambda x: second_most_common([_x.split(\"-\")[-1] for _x in x])\n).to_list()\n\n# Do the plot (3d or 2d)\nif N_DIMS==3:\n    fig = px.scatter_3d(\n        _df,  \n        x='PCA1',  y='PCA2', z='PCA3',\n        color=\"most_common_pii_detected\", \n        hover_data=['document', 'full_text']\n    )\nelse:\n    fig = px.scatter(\n        _df,  \n        x='PCA1',  y='PCA2',\n        color=\"most_common_pii_detected\", \n        hover_data=['document', 'full_text']\n    )\n    # Customize axis labels\n    fig.update_xaxes(title_text='<b>PCA1</b>')\n    fig.update_yaxes(title_text='<b>PCA2</b>')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:46:24.78558Z","iopub.execute_input":"2024-02-17T18:46:24.786074Z","iopub.status.idle":"2024-02-17T18:46:39.361408Z","shell.execute_reply.started":"2024-02-17T18:46:24.786023Z","shell.execute_reply":"2024-02-17T18:46:39.360437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_example(example, options=None, custom_css=None):\n    \"\"\"Visualize entities in a text using spaCy and displaCy.\n\n    Args:\n        example (dict | pd.Series): The example to visualize\n        options (dict, optional): The options for displacy rendering colours\n        custom_css (dict, optional): Additional customization\n    \"\"\"\n    if isinstance(example, pd.core.series.Series):\n        example = example.to_dict()\n    if not isinstance(example, dict):\n        raise ValueError(\"\\n... Example must be `dict` or `Series` ...\\n\")\n        \n    doc = spacy_nlp(example['full_text'])  # Tokenize the text with spaCy\n    entities = bio_to_spacy_entities(doc, example['labels'])\n    doc.ents = entities  # Update the doc's entities\n    \n    # Define custom CSS\n    custom_css = custom_css or \"\"\"\n    <style>    \n        /* Customizing entity appearance */\n        .entities {\n            font-size: 11px !important;\n            font-family: Verdana !important;\n            line-height: 1.25 !important;\n            border-radius: 10px !important; /* Rounded corners */\n            background-color: #f9f9f9 !important; /* Very light gray background */\n            padding: 20px 15px !important; /* Adjust padding */\n        }\n        /* Customizing entity appearance */\n        .entity {\n            font-size: 10px !important;\n            padding: 0.2em 0.4em !important;\n            font-family: Verdana !important;\n            font-weight: bold !important;\n            \n        }\n    </style>\n    \"\"\"\n\n    # Inject custom CSS\n    display(HTML(custom_css))\n    \n    # Visualization\n    displacy.render(\n        doc, \n        style=\"ent\", \n        options=options or COMPETITION_DISPLACY_OPTIONS, \n        jupyter=True\n    )\n\n\n\nprint(\"\\n... VISUALIZE THE FIRST EXAMPLE IN THE DATASET ...\\n\")\nvisualize_example(train_df.iloc[0])\n\nprint(\"\\n\\n... VISUALIZE THE EXAMPLE WITH THE MOST UNIQUE PII ...\\n\")\nvisualize_example(train_df.sort_values(by=[\"unique_pii_count\", \"total_pii_count\"], ascending=False).reset_index(drop=True).iloc[0])\n\nprint(\"\\n\\n... VISUALIZE THE EXAMPLE WITH THE MOST PII TOTAL ...\\n\")\nvisualize_example(train_df.sort_values(by=[\"total_pii_count\", \"unique_pii_count\"], ascending=False).reset_index(drop=True).iloc[0])","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:46:39.362955Z","iopub.execute_input":"2024-02-17T18:46:39.363668Z","iopub.status.idle":"2024-02-17T18:46:40.043291Z","shell.execute_reply.started":"2024-02-17T18:46:39.36363Z","shell.execute_reply":"2024-02-17T18:46:40.042217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the main dictionary\npii_data = {\n    'EMAIL':{},\n    'ID_NUM':{},\n    'NAME_STUDENT':{},\n    'PHONE_NUM':{},\n    'STREET_ADDRESS':{},\n    'URL_PERSONAL':{},\n    'USERNAME':{},\n}\n\ndef update_pii_data(pii_type, token, tokens, i):\n    if pii_type not in pii_data:\n        pii_data[pii_type] = {}\n    \n    # Extracting the token and surrounding context\n    token_text = tokens[i]\n    surrounding_tokens = tokens[max(0, i-2):i] + tokens[i+1:min(len(tokens), i+3)]\n    sentence = ' '.join(tokens)  # Simplified; consider a more accurate sentence detection\n    \n    # Assuming `tokens` is a list of all tokens in the document and `i` is the index of the current token\n    sentence_boundaries = [j for j, token in enumerate(tokens) if token in '.!?'] + [len(tokens)-1]\n    sentence_start = max([boundary for boundary in sentence_boundaries if boundary < i]+[0])\n    sentence_end = min([boundary for boundary in sentence_boundaries if boundary > i]+[len(tokens)-1])\n    sentence_context = tokens[sentence_start:sentence_end+1]\n    \n    # Determine PII position in the sentence\n    position_in_sentence = \"middle\"\n    if i == sentence_start:\n        position_in_sentence = \"beginning\"\n    elif i == sentence_end:\n        position_in_sentence = \"end\"\n    \n    # PII Token Type\n    if token_text.isalpha():\n        token_type = \"alphabetic\"\n    elif token_text.isdigit():\n        token_type = \"numeric\"\n    else:\n        token_type = \"alphanumeric\" if any(char.isalpha() for char in token_text) else \"other\"\n    \n    # PII Format Pattern\n    format_pattern = ''.join(['d' if char.isdigit() else 'l' if char.isalpha() else char for char in token_text])\n    \n    # Capitalization\n    capitalization = \"lowercase\"\n    if token_text.isupper():\n        capitalization = \"uppercase\"\n    elif token_text.istitle():\n        capitalization = \"titlecase\"\n    \n    # Special Characters\n    special_chars = any(not char.isalnum() for char in token_text)\n    \n    details = {\n        'token_text': token_text,\n        'surrounding_words': surrounding_tokens,\n        'location_in_essay': i,\n        'sentence_context': ' '.join(sentence_context),\n        'pii_length': len(token_text),\n        'position_in_sentence': position_in_sentence,\n        'token_type': token_type,\n        'format_pattern': format_pattern,\n        'capitalization': capitalization,\n        'special_chars': special_chars,\n        # Add more details as needed\n    }\n    \n    pii_token_key = f\"{token_text}_{i}\"  # Unique key for each PII instance\n    if pii_token_key not in pii_data[pii_type]:\n        pii_data[pii_type][pii_token_key] = []\n    pii_data[pii_type][pii_token_key].append(details)\n\n# Example of how to call this function within your iteration over the DataFrame\nfor index, row in tqdm(train_df.iterrows(), total=len(train_df)):\n    tokens = row['tokens']\n    labels = row['labels']\n    for i, label in enumerate(labels):\n        if label != 'O':  # If the label indicates PII\n            pii_type = label[2:]  # Extract PII type (removing the B- or I- prefix)\n            update_pii_data(pii_type, tokens[i], tokens, i)\n            \n            \n# Initialize an empty list to hold each PII instance as a dictionary\nflat_pii_data = []\n\n# Iterate through the pii_data dictionary\nfor pii_type, pii_instances in pii_data.items():\n    for instance_key, details_list in pii_instances.items():\n        for details in details_list:\n            # Create a flat dictionary for each PII instance\n            flat_instance = details.copy()  # Start with the existing details\n            flat_instance['pii_type'] = pii_type  # Add the PII type\n            flat_instance['instance_key'] = instance_key  # Add the instance key for reference\n            \n            # Append this flat dictionary to our list\n            flat_pii_data.append(flat_instance)\n\n# Store and viz\ntrain_pii_df = pd.DataFrame(flat_pii_data)\nprint(\"\\n... PII DATAFRAME ...\\n\")\ndisplay(train_pii_df)\n\n# Count the number of instances for each PII type\npii_type_counts = train_pii_df['pii_type'].value_counts()\nprint(\"\\n... PII TYPE COUNTS ...\\n\")\ndisplay(pii_type_counts.to_frame().T)\n\n# Or aggregate to find the average PII length by type\naverage_pii_length_by_type = train_pii_df.groupby('pii_type')['pii_length'].mean()\nprint(\"\\n\\n... AVERAGE PII LENGTH (CHARS) BY TYPE ...\\n\")\ndisplay(average_pii_length_by_type.to_frame().T)","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:46:40.045235Z","iopub.execute_input":"2024-02-17T18:46:40.046091Z","iopub.status.idle":"2024-02-17T18:46:42.088161Z","shell.execute_reply.started":"2024-02-17T18:46:40.04604Z","shell.execute_reply":"2024-02-17T18:46:42.087061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CORRELATION HEATMAP**\n\nLet's look at how various features of our known labels trend together. This should help us in identifying patterns or techniques that may be useful in creating models.\n\n* Remember, closer to 1 or -1 is worth noting. \n    * PII Length and Special Characters: \n        * You might spot a gentle nudge showing that the longer PII entities tend to get a bit fancy with special characters.\n        * This is probably related to emails or addresses sometimes requiring special characters and being longer.\n    * PII Types and Token Types:\n        * This is where it gets interesting. \n        * Some correlations could hint at certain PII types preferring certain token types. \n            * Like, EMAILs and alphanumeric tokens\n            * Or NAMEs being only alphabetic\n            * Or IDs being largely numeric\n            * etc.\n    * PII Types and PII Length: \n        * Some PII types might consistently appear longer or shorter than others.\n        \n**NOTE/WARNINGS:**\n\nWe must always watch Out for <b>Fake Friends</b> (Spurious Correlations)(Correlation != Causation): \n* Just because two things seem to move together doesn't mean they're actually influencing each other, especially with those one-hot encoded columns. \n* It's easy to get tricked into thinking there's a real connection when there isn't.\n\nSimplifying Categorical Variables: \n* We're glossing over the complexities of categorical variables here. \n* If you're after deeper insights, especially on how different categories play together, we will definitely need to explore beyond simple correlations. ","metadata":{}},{"cell_type":"code","source":"# Convert 'special_chars' to int\ntrain_pii_df['special_chars'] = train_pii_df['special_chars'].astype(int)\n\n# One-hot encode 'pii_type' and 'token_type'\npii_type_dummies = pd.get_dummies(train_pii_df['pii_type'], prefix='type', dtype=int)\ntoken_type_dummies = pd.get_dummies(train_pii_df['token_type'], prefix='token', dtype=int)\ncapitalization_dummies = pd.get_dummies(train_pii_df['capitalization'], prefix='capitalization', dtype=int)\nposition_dummies = pd.get_dummies(train_pii_df['position_in_sentence'], prefix='position', dtype=int)\n\n# Concatenate the original DataFrame with the new dummy DataFrames\nencoded_train_pii_df = pd.concat([train_pii_df, pii_type_dummies, token_type_dummies, capitalization_dummies, position_dummies], axis=1)\ndisplay(encoded_train_pii_df)\n\n# Get correlation matrix\ncorr_matrix = encoded_train_pii_df.corr(numeric_only=True)\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(corr_matrix, annot=False, cmap='coolwarm', linewidths=.5)\nplt.title('Correlation Matrix of PII Data')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:46:42.090091Z","iopub.execute_input":"2024-02-17T18:46:42.090411Z","iopub.status.idle":"2024-02-17T18:46:42.809392Z","shell.execute_reply.started":"2024-02-17T18:46:42.090384Z","shell.execute_reply":"2024-02-17T18:46:42.808196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Flatten the list of lists and join them into a single text string per surrounding words instance\ntexts = [' '.join(words) for words in train_pii_df['surrounding_words']]\n\n# Initialize CountVectorizer with bi-gram configuration\nvectorizer = CountVectorizer(ngram_range=(2, 2), stop_words='english')\n\n# Fit and transform the texts to extract bi-grams\nX = vectorizer.fit_transform(texts)\n\n# Sum up the counts of each bi-gram and convert to a list of (bi-gram, count)\nbi_grams_counts = [(bi_gram, X.toarray()[:, i].sum()) for bi_gram, i in vectorizer.vocabulary_.items()]\nbi_grams_counts = sorted(bi_grams_counts, key=lambda x: x[1], reverse=True)\n\nprint(\"\\n\\n... TOP TEN BIGRAMS ...\\n\")\nfor bi_gram, count in bi_grams_counts[:10]:\n    print(f\"{bi_gram}: {count}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:46:42.810692Z","iopub.execute_input":"2024-02-17T18:46:42.811055Z","iopub.status.idle":"2024-02-17T18:46:55.29085Z","shell.execute_reply.started":"2024-02-17T18:46:42.811013Z","shell.execute_reply":"2024-02-17T18:46:55.289673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTE:**\n* In this word cloud, the size of each bi-gram phrase represents its frequency. \n* Word clouds allow you to quickly grasp which phrases are most common around PII\n* The underscores in the bi_grams_string replace spaces to ensure bi-grams are treated as single entities in the word cloud.","metadata":{}},{"cell_type":"code","source":"# Generate a single string for the word cloud input\nbi_grams_string = ' '.join(['_'.join(bi_gram.split()) for bi_gram, count in bi_grams_counts for _ in range(count)])\n\n# Create and display the word cloud\nwordcloud = WordCloud(width = 1200, height = 600, background_color ='white').generate(bi_grams_string)\n\nplt.figure(figsize=(20, 10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:46:55.295149Z","iopub.execute_input":"2024-02-17T18:46:55.295783Z","iopub.status.idle":"2024-02-17T18:46:57.514294Z","shell.execute_reply.started":"2024-02-17T18:46:55.295742Z","shell.execute_reply":"2024-02-17T18:46:57.513226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TFIDF_N_FEATURES = 10_000\nSKLEARN_SEED = 42\nK = 10  # How many clusters\n\n# Create our vectorized dataset\ntexts = train_pii_df['sentence_context'].tolist()\ntfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=TFIDF_N_FEATURES)\nX_tfidf = tfidf_vectorizer.fit_transform(texts)\n\n# Fit the clustering model to our vectorized data\nkmeans = KMeans(n_clusters=K, random_state=SKLEARN_SEED)\nclusters = kmeans.fit_predict(X_tfidf)\n\n# Since we used PCA for a different viz earlier... let's try TSNE\n# t-SNE operates on dense matrices, hence the conversion\ntsne = TSNE(n_components=2, random_state=SKLEARN_SEED)\nX_tsne = tsne.fit_transform(X_tfidf.toarray())","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:46:57.515725Z","iopub.execute_input":"2024-02-17T18:46:57.51654Z","iopub.status.idle":"2024-02-17T18:47:15.506383Z","shell.execute_reply.started":"2024-02-17T18:46:57.516506Z","shell.execute_reply":"2024-02-17T18:47:15.50537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare hover text data\nMAX_CONTEXT_LEN = 100\nhover_texts = [\n    f\"PII Type: {pii_type}<br>Text: {text}<br>Context: {context[:MAX_CONTEXT_LEN]}...\"\n    for pii_type, text, context in \n    zip(train_pii_df['pii_type'], train_pii_df['token_text'], train_pii_df['sentence_context'])\n]\n\n\n# Generate a list of colors, one for each cluster (might... be ugly)\ncolors = px.colors.qualitative.Plotly[:K]\nif len(colors)<K:\n    raise ValueError(f\"\\n... Pick a different CMAP there are only {len(colors)} colors in this one vs the K={K} needed\")\n\n# Init\nfig = go.Figure()\n\n# Iterate over each cluster and add the trace\nfor k, color in zip(range(K), colors):\n    mask = clusters == k\n    fig.add_trace(go.Scatter(\n        x=X_tsne[mask, 0], \n        y=X_tsne[mask, 1],\n        mode='markers', \n        marker=dict(color=color),\n        name=f'Cluster {k}', \n        text=np.array(hover_texts)[mask],\n        hoverinfo='text'\n    ))  \n    \n# Titles and whatnot\nfig.update_layout(\n    title='<b>Clusters of PII Contexts</b>',\n    xaxis_title=\"<b>t-SNE Dimension 1</b>\",\n    yaxis_title=\"<b>t-SNE Dimension 2</b>\",\n    legend_title=\"<b>Clusters</b>\",\n    hovermode='closest'  # Hover is activated closest to the mouse for better readability\n)  \n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:47:15.507624Z","iopub.execute_input":"2024-02-17T18:47:15.508279Z","iopub.status.idle":"2024-02-17T18:47:15.586854Z","shell.execute_reply.started":"2024-02-17T18:47:15.508248Z","shell.execute_reply":"2024-02-17T18:47:15.58572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add relative position in the essay to use for plotting\ntrain_pii_df['relative_position'] = train_pii_df['location_in_essay'] / train_pii_df['location_in_essay'].max()\n\nN_BINS = 200\nfig = px.histogram(train_pii_df, x='relative_position', color='pii_type',\n                   nbins=N_BINS,\n                   histnorm='percent',  # Normalize to show percentages\n                   barmode='overlay',   # Overlay the histograms to compare PII types\n                   opacity=0.75,        # Adjust opacity to make overlapping bars more visible\n                   labels={'relative_position': 'Relative Position in Text'},\n                   title='Distribution of PII Types Across Texts')\n\n# Improve clarity with additional layout adjustments\nfig.update_layout(xaxis_title='Relative Position in Text',\n                  yaxis_title='Percentage of Instances',\n                  xaxis=dict(tickmode='array',\n                             tickvals=[0, 0.25, 0.5, 0.75, 1],\n                             ticktext=['Start', '25%', 'Middle', '75%', 'End']),\n                  legend_title_text='PII Type')\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:47:15.588299Z","iopub.execute_input":"2024-02-17T18:47:15.588613Z","iopub.status.idle":"2024-02-17T18:47:15.746446Z","shell.execute_reply.started":"2024-02-17T18:47:15.588586Z","shell.execute_reply":"2024-02-17T18:47:15.745391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of segments to group location into (must match label length if we want annotated heatmap)\nN_SEGMENTS = len(COMPETITION_LABELS)\nCMAP = \"viridis\"\n\n# Assign each PII instance to a segment based on its relative position\ntrain_pii_df['loc_segment'] = np.floor(train_pii_df['relative_position'] * N_SEGMENTS).astype(int)\n\n# Ensure segment numbers do not exceed N_SEGMENTS - 1\ntrain_pii_df['loc_segment'] = train_pii_df['loc_segment'].clip(upper=N_SEGMENTS - 1)\n\n# Create a pivot table with PII types as columns, segments as rows, and counts as values\nheatmap_data = pd.pivot_table(\n    train_pii_df, \n    values='token_text', \n    index='loc_segment',\n    columns='pii_type', \n    aggfunc='count', \n    fill_value=0\n)\n\n# Normalize\nfor c in heatmap_data:\n    max_col_value = heatmap_data[c].max()\n    heatmap_data[c] = np.round(heatmap_data[c].apply(lambda x: x/max_col_value), 10)\n\n\n\n# Use the pivot table to create the heatmap\nfig = ff.create_annotated_heatmap(\n    z=heatmap_data.values, \n    x=heatmap_data.columns.tolist(),\n    y=[f'Segment <b>{i+1}</b>' for i in range(N_SEGMENTS)],\n    annotation_text=heatmap_data.values, \n    colorscale=CMAP\n)\n\n# Updating layout for clarity\nfig.update_layout(title='<b>Heatmap of PII Distribution Across Text Segments</b>',\n                  xaxis=dict(title='<b>PII Type</b>'),\n                  yaxis=dict(title='<b>Location In Essay</b> (1=Start, 7=End)'),\n                  yaxis_autorange='reversed')\n\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:47:15.748216Z","iopub.execute_input":"2024-02-17T18:47:15.748645Z","iopub.status.idle":"2024-02-17T18:47:15.851467Z","shell.execute_reply.started":"2024-02-17T18:47:15.748607Z","shell.execute_reply":"2024-02-17T18:47:15.850334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Number of segments to group location into - go for more fine grained (doesn't have to be square since no annotation)\nN_SEGMENTS = 20\n\n# Assign each PII instance to a segment based on its relative position\ntrain_pii_df['loc_segment'] = np.floor(train_pii_df['relative_position'] * N_SEGMENTS).astype(int)\n\n# Ensure segment numbers do not exceed N_SEGMENTS - 1\ntrain_pii_df['loc_segment'] = train_pii_df['loc_segment'].clip(upper=N_SEGMENTS - 1)\n\nheatmap_data = pd.pivot_table(\n    train_pii_df, \n    values='token_text', \n    index='loc_segment',\n    columns='pii_type', \n    aggfunc='count', \n    fill_value=0\n).reindex(range(N_SEGMENTS), fill_value=0)\n\n# Normalize\nlog_transformed_values = np.log(heatmap_data.values + 1)\n\n# Convert the pivot table's row and column names to string format for better display\n# PII types and Segment Location respectively\nx = heatmap_data.columns.astype(str).tolist()  \ny = heatmap_data.index.astype(str).tolist()\n\n# Create the heatmap\nfig = go.Figure(data=go.Heatmap(\n    x=x, y=y, z=log_transformed_values,\n    colorscale=CMAP, \n    colorbar=dict(title='Log(Count + 1)')\n))\n\n# Updating layout for clarity\nfig.update_layout(\n    title='<b>Heatmap of PII Distribution Across Text Segments</b>',\n    xaxis=dict(title='<b>PII Type</b>'),\n    yaxis=dict(title='<b>Location In Essay</b> (0=Start, 20=End)'),\n    yaxis_autorange='reversed'\n)\n\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-17T18:47:15.852705Z","iopub.execute_input":"2024-02-17T18:47:15.85307Z","iopub.status.idle":"2024-02-17T18:47:15.898189Z","shell.execute_reply.started":"2024-02-17T18:47:15.853037Z","shell.execute_reply":"2024-02-17T18:47:15.897046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"baseline\"></a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: #f4b37a;\" id=\"baseline\">6&nbsp;&nbsp;BASELINE&nbsp;&nbsp;&nbsp;&nbsp;<a style=\"text-decoration: none; color: #f8d2b0;\" href=\"#toc\">&#10514;</a></h1>\n\n<br>\n\nOur baseline solution offers the following approach.\n\n1. Define some basic regex patterns to identify various forms of PII\n2. Identify common words in the training dataset (these will be forced to be 'O')\n3. Write a function to identify PII and apply precedence to pieces of text (not tokens)\n4. Map these identified PII chunks to the underlying tokens and ensure BIO is appropriately generated.\n5. Force all individual tokens that are in the common word list to be 'O'\n\n**Let's make some super simple assumptions about pii to get a baseline solution to test the process**\n\n* Every capitalized word is: **`NAME_STUDENT`**\n* Any token with 'www' or 'http' is: **`URL_PERSONAL`**\n* Any token with 5 or more numbers that is not one of the other pii types is: **`ID_NUM`**\n* Any token with @ in it and ending with .com is: **`EMAIL`**\n* We pull a common/terrible **`STREET_ADDRESS`** regex to use.\n* If the regex for phone number triggers (xxxyyyzzzz with any combination of brackets, dots, dashes, etc.)\n* No tokens are assumed to be **`USERNAME`**\n\n---\n\n<br>\n\n<b>NOTE:</b> \n* Version 1 (above) is alright... but I think a better/faster approach would be to work in a subtractive manner (start with highest precedence PII and remove that text from the text as a whole). \n* I also think we should implement lookahead. i.e. if we detect a name/address/email in one part of the text, we should check for any of the subtokens of that PII to occur later in the text and subsequently identify those as well.\n\n<br>","metadata":{"papermill":{"duration":0.051241,"end_time":"2024-02-10T16:14:12.347724","exception":false,"start_time":"2024-02-10T16:14:12.296483","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">6.1 <b>PATTERN-BASED</b> APPROACH</h3>\n<hr><br>\n\n<br>","metadata":{}},{"cell_type":"markdown","source":"**Get common words**","metadata":{}},{"cell_type":"code","source":"USE_DATASET_FOR_COMMON=True\nREMOVE_NAMES_FROM_COMMON_LIST=True\n\nif USE_DATASET_FOR_COMMON:\n    most_common_tokens = list(pd.read_csv(\"/kaggle/input/english-word-frequency/unigram_freq.csv\").values)\nelse:\n    # Concatenate all the processed texts into a single list\n    all_tokens = flatten_l_o_l(train_df['tokens'].to_list())\n\n    # Count the words\n    token_counts = Counter(all_tokens)\n\n    # Get the 11_500 most common words (approximately down to a 10 count)\n    most_common_tokens = token_counts.most_common(11_500)\n\n# Print the 10 most-common 'common' tokens\nprint(\"\\n... 10 MOST-COMMON 'COMMON' TOKENS ...\")\nfor tok, count in most_common_tokens[:10]:\n    print(\"\\t-->\", repr(tok), count)\n\n# Print the 10 least-common 'common' tokens\nprint(\"\\n... 10 LEAST-COMMON 'COMMON' TOKENS ...\")\nfor tok, count in most_common_tokens[-10:]:\n    print(\"\\t-->\", repr(tok), count)\n\nCOMMON_TOKENS = [x[0] for x in most_common_tokens]\n\nif REMOVE_NAMES_FROM_COMMON_LIST:\n    names = pd.read_csv(\"/kaggle/input/us-baby-names/NationalNames.csv\")[\"Name\"].to_list()\n    COMMON_TOKENS = list(set(COMMON_TOKENS) - set(names+[x.lower() for x in names]))\n\nprint(len(COMMON_TOKENS))","metadata":{"execution":{"iopub.status.busy":"2024-02-17T20:26:57.166674Z","iopub.execute_input":"2024-02-17T20:26:57.167747Z","iopub.status.idle":"2024-02-17T20:27:00.803636Z","shell.execute_reply.started":"2024-02-17T20:26:57.167694Z","shell.execute_reply":"2024-02-17T20:27:00.801896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Define some regex and functions to create a baseline submission**\n\nI also created a dataclass with some useful information for each if you want to learn how it all works.","metadata":{}},{"cell_type":"code","source":"address_components = [\n    \"west\", \"sw\", \"suite\", \"street\", \"ste\", \"st\", \"south\", \n    \"se\", \"road\", \"rd\", \"pt\", \"point\", \"place\", \"pl\", \"pkwy\", \n    \"parkway\", \"nw\", \"north\", \"ne\", \"ln\", \"lane\", \"hwy\", \"highway\", \"fwy\", \"freeway\", \"east\", \"drive\", \"ctr\", \"ct\", \"court\", \"circle\", \"cir\", \"center\", \"building\", \"boulevard\", \"blvd\", \"bldg\", \"avenue\", \"ave\", \"apt\", \"apartment\", \"alley\", \"aly\", \"annex\", \"anx\", \"arcade\", \"arc\", \"bayou\", \"byu\", \"beach\", \"bch\", \"bend\", \"bnd\", \"bluff\", \"blf\", \"bluffs\", \"blfs\", \"bot\", \"btm\", \"branch\", \"br\", \"bridge\", \"brg\", \"brook\", \"brk\", \"brooks\", \"brks\", \"burg\", \"bg\", \"burgs\", \"bgs\", \"bypass\", \"byp\", \"camp\", \"cp\", \"canyon\", \"cyn\", \"cape\", \"cpe\", \"causeway\", \"cswy\", \"centers\", \"ctrs\", \"cliff\", \"clf\", \"cliffs\", \"clfs\", \"club\", \"clb\", \"common\", \"cmn\", \"commons\", \"cmns\", \"corner\", \"cor\", \"corners\", \"cors\", \"course\", \"crse\", \"courts\", \"cts\", \"cove\", \"cv\", \"coves\", \"cvs\", \"creek\", \"crk\", \"crescent\", \"cres\", \"crest\", \"crst\", \"crossing\", \"xing\", \"crossroad\", \"xrd\", \"curve\", \"curv\", \"dale\", \"dl\", \"dam\", \"dm\", \"divide\", \"dv\", \"drives\", \"drs\", \"estate\", \"est\", \"estates\", \"ests\", \"expressway\", \"expy\", \"extension\", \"ext\", \"extensions\", \"exts\", \"fall\", \"falls\", \"fls\", \"ferry\", \"fry\", \"field\", \"fld\", \"fields\", \"flds\", \"flat\", \"flt\", \"flats\", \"flts\", \"ford\", \"frd\", \"fords\", \"frds\", \"forest\", \"frst\", \"forge\", \"frg\", \"forges\", \"frgs\", \"fork\", \"frk\", \"forks\", \"frks\", \"fort\", \"ft\", \"garden\", \"gdn\", \"gardens\", \"gdns\", \"gateway\", \"gtwy\", \"glen\", \"gln\", \"glens\", \"glns\", \"green\", \"grn\", \"greens\", \"grns\", \"grove\", \"grv\", \"groves\", \"grvs\", \"harbor\", \"hbr\", \"harbors\", \"hbrs\", \"haven\", \"hvn\", \"heights\", \"hts\", \"hill\", \"hl\", \"hills\", \"hls\", \"hollow\", \"holw\", \"inlet\", \"inlt\", \"island\", \"isl\", \"islands\", \"isls\", \"isle\", \"junction\", \"jct\", \"junctions\", \"jcts\", \"key\", \"ky\", \"keys\", \"kys\", \"knoll\", \"knl\", \"knolls\", \"knls\", \"lake\", \"lk\", \"lakes\", \"lks\", \"land\", \"landing\", \"lndg\", \"light\", \"lgt\", \"lights\", \"lgts\", \"loaf\", \"lf\", \"lock\", \"lck\", \"locks\", \"lcks\", \"lodge\", \"ldg\", \"loop\", \"mall\", \"manor\", \"mnr\", \"manors\", \"mnrs\", \"meadow\", \"mdw\", \"meadows\", \"mdws\", \"mere\", \"mews\", \"mill\", \"mills\", \"mission\", \"msn\", \"motorway\", \"mtwy\", \"mount\", \"mt\", \"mountain\", \"mtn\", \"mountains\", \"mtns\", \"neck\", \"nck\", \"orchard\", \"orch\", \"oval\", \"overpass\", \"opas\", \"park\", \"parks\", \"pass\", \"passage\", \"psge\", \"path\", \"pike\", \"pine\", \"pne\", \"pines\", \"pnes\", \"plain\", \"pln\", \"plains\", \"plns\", \"plaza\", \"plz\", \"points\", \"pts\", \"port\", \"prt\", \"ports\", \"prts\", \"prairie\", \"pr\", \"radial\", \"radl\", \"ramp\", \"ridge\", \"rdg\", \"ridges\", \"rdgs\", \"river\", \"riv\", \"roads\", \"rds\", \"route\", \"rte\", \"row\", \"rue\", \"run\", \"shoal\", \"shl\", \"shoals\", \"shls\", \"shore\", \"shr\", \"shores\", \"shrs\", \"skyway\", \"skwy\", \"spring\", \"spg\", \"springs\", \"spgs\", \"spur\", \"spurs\", \"square\", \"sq\", \"squares\", \"sqs\", \"station\", \"sta\", \"stravenue\", \"stra\", \"stream\", \"strm\", \"streets\", \"sts\", \"summit\", \"smt\", \"terrace\", \"ter\", \"throughway\", \"trwy\", \"trace\", \"trce\", \"track\", \"trak\", \"trafficway\", \"trfy\", \"trail\", \"trl\", \"trailer\", \"trlr\", \"tunnel\", \"tunl\", \"turnpike\", \"tpke\", \"underpass\", \"upas\", \"valley\", \"vly\", \"valleys\", \"vlys\", \"viaduct\", \"via\", \"view\", \"vw\", \"views\", \"vws\", \"village\", \"vlg\", \"villages\", \"vlgs\", \"ville\", \"vl\", \"vista\", \"vis\", \"walk\", \"walks\", \"wall\", \"way\", \"ways\", \"well\", \"wl\", \"wells\", \"wls\"\n]\n\n# Adding a selection of US state abbreviations, Canadian province abbreviations, and a few country names\nadditional_components = [\n    \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\",\n    \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\",\n    \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n    \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\",\n    \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\",\n    \"AB\", \"BC\", \"MB\", \"NB\", \"NL\", \"NS\", \"NT\", \"NU\", \"ON\", \"PE\",\n    \"QC\", \"SK\", \"YT\", \"USA\", \"Canada\", \"Mexico\", \"United States of America\", \"The Netherlands\", \"United Kingdom\",\n]\n\n# Combine the lists\ncomplete_address_components = [x.upper() for x in address_components + additional_components] + [x.title() for x in address_components + additional_components]\npattern = r'\\b(?:' + '|'.join(re.escape(word) for word in complete_address_components) + r')\\b'\n\n# Compile the regex with the IGNORECASE flag\nregex = re.compile(pattern, re.IGNORECASE)\nregex","metadata":{"execution":{"iopub.status.busy":"2024-02-17T20:28:43.933925Z","iopub.execute_input":"2024-02-17T20:28:43.934432Z","iopub.status.idle":"2024-02-17T20:28:44.041549Z","shell.execute_reply.started":"2024-02-17T20:28:43.934399Z","shell.execute_reply":"2024-02-17T20:28:44.040297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This will be for understanding\n@dataclass\nclass RegexPattern:\n    regex: str\n    name: str\n    description: str\n    detailed_explanation: str\n    step_by_step_explanation: str\n    eli5_example_explanation: str\n    potential_improvements: str\n\n\nstreet_address_pattern = RegexPattern(\n    regex=re.compile(r'\\b(?:WEST|SW|SUITE|STREET|STE|ST|SOUTH|SE|ROAD|RD|PT|POINT|PLACE|PL|PKWY|PARKWAY|NW|NORTH|NE|LN|LANE|HWY|HIGHWAY|FWY|FREEWAY|EAST|DRIVE|CTR|CT|COURT|CIRCLE|CIR|CENTER|BUILDING|BOULEVARD|BLVD|BLDG|AVENUE|AVE|APT|APARTMENT|ALLEY|ALY|ANNEX|ANX|ARCADE|ARC|BAYOU|BYU|BEACH|BCH|BEND|BND|BLUFF|BLF|BLUFFS|BLFS|BOT|BTM|BRANCH|BR|BRIDGE|BRG|BROOK|BRK|BROOKS|BRKS|BURG|BG|BURGS|BGS|BYPASS|BYP|CAMP|CP|CANYON|CYN|CAPE|CPE|CAUSEWAY|CSWY|CENTERS|CTRS|CLIFF|CLF|CLIFFS|CLFS|CLUB|CLB|COMMON|CMN|COMMONS|CMNS|CORNER|COR|CORNERS|CORS|COURSE|CRSE|COURTS|CTS|COVE|CV|COVES|CVS|CREEK|CRK|CRESCENT|CRES|CREST|CRST|CROSSING|XING|CROSSROAD|XRD|CURVE|CURV|DALE|DL|DAM|DM|DIVIDE|DV|DRIVES|DRS|ESTATE|EST|ESTATES|ESTS|EXPRESSWAY|EXPY|EXTENSION|EXT|EXTENSIONS|EXTS|FALL|FALLS|FLS|FERRY|FRY|FIELD|FLD|FIELDS|FLDS|FLAT|FLT|FLATS|FLTS|FORD|FRD|FORDS|FRDS|FOREST|FRST|FORGE|FRG|FORGES|FRGS|FORK|FRK|FORKS|FRKS|FORT|FT|GARDEN|GDN|GARDENS|GDNS|GATEWAY|GTWY|GLEN|GLN|GLENS|GLNS|GREEN|GRN|GREENS|GRNS|GROVE|GRV|GROVES|GRVS|HARBOR|HBR|HARBORS|HBRS|HAVEN|HVN|HEIGHTS|HTS|HILL|HL|HILLS|HLS|HOLLOW|HOLW|INLET|INLT|ISLAND|ISL|ISLANDS|ISLS|ISLE|JUNCTION|JCT|JUNCTIONS|JCTS|KEY|KY|KEYS|KYS|KNOLL|KNL|KNOLLS|KNLS|LAKE|LK|LAKES|LKS|LAND|LANDING|LNDG|LIGHT|LGT|LIGHTS|LGTS|LOAF|LF|LOCK|LCK|LOCKS|LCKS|LODGE|LDG|LOOP|MALL|MANOR|MNR|MANORS|MNRS|MEADOW|MDW|MEADOWS|MDWS|MERE|MEWS|MILL|MILLS|MISSION|MSN|MOTORWAY|MTWY|MOUNT|MT|MOUNTAIN|MTN|MOUNTAINS|MTNS|NECK|NCK|ORCHARD|ORCH|OVAL|OVERPASS|OPAS|PARK|PARKS|PASS|PASSAGE|PSGE|PATH|PIKE|PINE|PNE|PINES|PNES|PLAIN|PLN|PLAINS|PLNS|PLAZA|PLZ|POINTS|PTS|PORT|PRT|PORTS|PRTS|PRAIRIE|PR|RADIAL|RADL|RAMP|RIDGE|RDG|RIDGES|RDGS|RIVER|RIV|ROADS|RDS|ROUTE|RTE|ROW|RUE|RUN|SHOAL|SHL|SHOALS|SHLS|SHORE|SHR|SHORES|SHRS|SKYWAY|SKWY|SPRING|SPG|SPRINGS|SPGS|SPUR|SPURS|SQUARE|SQ|SQUARES|SQS|STATION|STA|STRAVENUE|STRA|STREAM|STRM|STREETS|STS|SUMMIT|SMT|TERRACE|TER|THROUGHWAY|TRWY|TRACE|TRCE|TRACK|TRAK|TRAFFICWAY|TRFY|TRAIL|TRL|TRAILER|TRLR|TUNNEL|TUNL|TURNPIKE|TPKE|UNDERPASS|UPAS|VALLEY|VLY|VALLEYS|VLYS|VIADUCT|VIA|VIEW|VW|VIEWS|VWS|VILLAGE|VLG|VILLAGES|VLGS|VILLE|VL|VISTA|VIS|WALK|WALKS|WALL|WAY|WAYS|WELL|WL|WELLS|WLS|AL|AK|AZ|AR|CA|CO|CT|DE|FL|GA|HI|ID|IL|IN|IA|KS|KY|LA|ME|MD|MA|MI|MN|MS|MO|MT|NE|NV|NH|NJ|NM|NY|NC|ND|OH|OK|OR|PA|RI|SC|SD|TN|TX|UT|VT|VA|WA|WV|WI|WY|AB|BC|MB|NB|NL|NS|NT|NU|ON|PE|QC|SK|YT|USA|CANADA|MEXICO|UNITED\\ STATES\\ OF\\ AMERICA|THE\\ NETHERLANDS|UNITED\\ KINGDOM|West|Sw|Suite|Street|Ste|St|South|Se|Road|Rd|Pt|Point|Place|Pl|Pkwy|Parkway|Nw|North|Ne|Ln|Lane|Hwy|Highway|Fwy|Freeway|East|Drive|Ctr|Ct|Court|Circle|Cir|Center|Building|Boulevard|Blvd|Bldg|Avenue|Ave|Apt|Apartment|Alley|Aly|Annex|Anx|Arcade|Arc|Bayou|Byu|Beach|Bch|Bend|Bnd|Bluff|Blf|Bluffs|Blfs|Bot|Btm|Branch|Br|Bridge|Brg|Brook|Brk|Brooks|Brks|Burg|Bg|Burgs|Bgs|Bypass|Byp|Camp|Cp|Canyon|Cyn|Cape|Cpe|Causeway|Cswy|Centers|Ctrs|Cliff|Clf|Cliffs|Clfs|Club|Clb|Common|Cmn|Commons|Cmns|Corner|Cor|Corners|Cors|Course|Crse|Courts|Cts|Cove|Cv|Coves|Cvs|Creek|Crk|Crescent|Cres|Crest|Crst|Crossing|Xing|Crossroad|Xrd|Curve|Curv|Dale|Dl|Dam|Dm|Divide|Dv|Drives|Drs|Estate|Est|Estates|Ests|Expressway|Expy|Extension|Ext|Extensions|Exts|Fall|Falls|Fls|Ferry|Fry|Field|Fld|Fields|Flds|Flat|Flt|Flats|Flts|Ford|Frd|Fords|Frds|Forest|Frst|Forge|Frg|Forges|Frgs|Fork|Frk|Forks|Frks|Fort|Ft|Garden|Gdn|Gardens|Gdns|Gateway|Gtwy|Glen|Gln|Glens|Glns|Green|Grn|Greens|Grns|Grove|Grv|Groves|Grvs|Harbor|Hbr|Harbors|Hbrs|Haven|Hvn|Heights|Hts|Hill|Hl|Hills|Hls|Hollow|Holw|Inlet|Inlt|Island|Isl|Islands|Isls|Isle|Junction|Jct|Junctions|Jcts|Key|Ky|Keys|Kys|Knoll|Knl|Knolls|Knls|Lake|Lk|Lakes|Lks|Land|Landing|Lndg|Light|Lgt|Lights|Lgts|Loaf|Lf|Lock|Lck|Locks|Lcks|Lodge|Ldg|Loop|Mall|Manor|Mnr|Manors|Mnrs|Meadow|Mdw|Meadows|Mdws|Mere|Mews|Mill|Mills|Mission|Msn|Motorway|Mtwy|Mount|Mt|Mountain|Mtn|Mountains|Mtns|Neck|Nck|Orchard|Orch|Oval|Overpass|Opas|Park|Parks|Pass|Passage|Psge|Path|Pike|Pine|Pne|Pines|Pnes|Plain|Pln|Plains|Plns|Plaza|Plz|Points|Pts|Port|Prt|Ports|Prts|Prairie|Pr|Radial|Radl|Ramp|Ridge|Rdg|Ridges|Rdgs|River|Riv|Roads|Rds|Route|Rte|Row|Rue|Run|Shoal|Shl|Shoals|Shls|Shore|Shr|Shores|Shrs|Skyway|Skwy|Spring|Spg|Springs|Spgs|Spur|Spurs|Square|Sq|Squares|Sqs|Station|Sta|Stravenue|Stra|Stream|Strm|Streets|Sts|Summit|Smt|Terrace|Ter|Throughway|Trwy|Trace|Trce|Track|Trak|Trafficway|Trfy|Trail|Trl|Trailer|Trlr|Tunnel|Tunl|Turnpike|Tpke|Underpass|Upas|Valley|Vly|Valleys|Vlys|Viaduct|Via|View|Vw|Views|Vws|Village|Vlg|Villages|Vlgs|Ville|Vl|Vista|Vis|Walk|Walks|Wall|Way|Ways|Well|Wl|Wells|Wls|Al|Ak|Az|Ar|Ca|Co|Ct|De|Fl|Ga|Hi|Id|Il|In|Ia|Ks|Ky|La|Me|Md|Ma|Mi|Mn|Ms|Mo|Mt|Ne|Nv|Nh|Nj|Nm|Ny|Nc|Nd|Oh|Ok|Or|Pa|Ri|Sc|Sd|Tn|Tx|Ut|Vt|Va|Wa|Wv|Wi|Wy|Ab|Bc|Mb|Nb|Nl|Ns|Nt|Nu|On|Pe|Qc|Sk|Yt|Usa|Canada|Mexico|United\\ States\\ Of\\ America|The\\ Netherlands|United\\ Kingdom)\\b', re.IGNORECASE|re.UNICODE),\n    name=\"STREET_ADDRESS\",\n    description=\"Matches a broad range of US street addresses, capturing elements from building numbers to street types, and extending to city and state codes with ZIP codes.\",\n    detailed_explanation=r\"This regex is designed to comprehensively match various components of U.S. street addresses, starting with the building or house number, followed by street names that may include multiple words or abbreviations for street types (e.g., Ave, Blvd). It also matches address modifiers like suite numbers and extends to capture city, state, and ZIP code information. The inclusion of a wide array of street types and other address-related keywords enhances its ability to accurately identify addresses within text.\",\n    step_by_step_explanation=r\"\"\"  1. `[0-9]{1,9}` matches the building or house number at the start, allowing for up to 9 digits to accommodate a wide range of number formats.\n  2. `.*` serves as a wildcard to match any characters (including spaces) between the building number and the next identifiable part of the address, allowing for flexibility in address formatting.\n  3. The long list of street types and address-related keywords (e.g., 'street', 'avenue', 'suite', etc.) matches various possible descriptors in an address, making the regex versatile in identifying address components.\n  4. `[\\., ]{0,2}` allows for up to two optional separators (periods, commas, or spaces) following the street type, accommodating common punctuation used in addresses.\n  5. `[0-9]{0,7}` optionally matches a secondary number, such as an apartment or suite number, following the street type, allowing for up to 7 digits.\n  6. `.*,` matches any characters leading up to a comma, which is often used before the city name in addresses.\n  7. `\\s*([A-Z]{2})\\s` matches the state abbreviation, requiring it to be two capital letters with optional leading and trailing spaces.\n  8. `[0-9]{5}(-[0-9]{4})?` matches the ZIP code, which can be either 5 digits or 9 digits with a hyphen separating the additional four digits (ZIP+4 format).\"\"\",\n    eli5_example_explanation=\"This pattern is like a detective looking for clues to find where someone lives. It starts by finding the house number, then looks for the street name, and doesn't stop until it has figured out the city, state, and even the ZIP code. It knows lots of street names and types, and even understands if there's an apartment number or if the address is written with some extra bits like commas or periods.\",\n    potential_improvements=\"n/a\"\n)\n\n\nname_student_pattern = RegexPattern(\n    regex=re.compile(r'\\b[A-Z][a-z]+(?:\\s[A-Z][a-z]+)*\\b', re.DOTALL),\n    name=\"NAME_STUDENT\",\n    description=\"Matches student names with initial capital letters, potentially including first and last names, or middle names, without capturing initials or single-letter names.\",\n    detailed_explanation=\"This pattern is tailored to capture names that start with a capital letter followed by lowercase letters, which can include first names, middle names, and last names.\",\n    step_by_step_explanation=r\"\"\"  1. `\\b` matches the start of a word boundary, ensuring the name is standalone.\n  2. `[A-Z]` matches the first letter of the name, which must be uppercase.\n  3. `[a-z]+` matches the remaining letters of the first name, which are lowercase.\n  4. `(?:\\s[A-Z][a-z]+)*` matches zero or more occurrences of middle or last names, each beginning with a space followed by an uppercase letter and then lowercase letters.\n  5. `\\b` matches the end of a word boundary, ensuring the name is standalone.\"\"\",\n    eli5_example_explanation=\"This is like looking for a friend's name in a list, where each name starts with a big letter (like 'S' in Sarah) and the rest are small letters (like 'arah' in Sarah).\",\n    potential_improvements=\"Consider adding support for names with apostrophes, hyphens (e.g., O'Neill, Jean-Luc), and names from different cultures that might not follow the first-letter-uppercase convention.\"\n)\n\n\nid_num_pattern = RegexPattern(\n    regex=re.compile(r'[A-Za-z]*\\d{5,}[A-Za-z0-9]*', re.DOTALL),\n    name=\"ID_NUM\",\n    description=\"Matches ID numbers with an optional leading alphabetic prefix, a mandatory sequence of at least 5 digits, and an optional alphanumeric tail.\",\n    detailed_explanation=\"This pattern identifies IDs that may start with letters (optional), followed by a core of 5 or more digits, and can end with any combination of letters and numbers.\",\n    step_by_step_explanation=r\"\"\"  1. `[A-Za-z]*` optionally matches any leading letters.\n  2. `\\d{5,}` requires a sequence of at least 5 digits, forming the ID's core.\n  3. `[A-Za-z0-9]*` allows for any trailing alphanumeric characters, accommodating a variety of ID formats.\"\"\",\n    eli5_example_explanation=\"Imagine you have a special code for your library card. This pattern helps find those codes, even if they start with some letters, then have a bunch of numbers, and might end with more letters or numbers.\",\n    potential_improvements=\"Could be improved to handle IDs with specific formats or separators (like dashes or dots) between segments.\"\n)\n\n\nphone_num_pattern = RegexPattern(\n    regex=re.compile(r'(\\+?\\d{1,3}[ _.-]?)?(\\(?\\d{3}\\)?[ _.-]?)?(\\d{3}[ _.-]?\\d{4})', re.DOTALL),\n    name=\"PHONE_NUM\",\n    description=\"Matches phone numbers in various formats, supporting optional country codes, area codes (with or without parentheses), and separators like space, dash, or dot.\",\n    detailed_explanation=\"This pattern can capture phone numbers including those with country codes, area codes, and various separator characters. It's flexible enough to match many international formats.\",\n    step_by_step_explanation=r\"\"\"  1. `(\\+?\\d{1,3}[ _.-]?)?` matches an optional country code, possibly preceded by a plus sign and followed by a separator.\n  2. `(\\(?\\d{3}\\)?[ _.-]?)?` matches an optional area code, which might be enclosed in parentheses, followed by a separator.\n  3. `(\\d{3}[ _.-]?\\d{4})` captures the main part of the phone number, allowing for a separator between the first three digits and the last four.\"\"\",\n    eli5_example_explanation=\"If you're looking at a list of phone numbers, this pattern helps find them all, no matter if they're long or short, have special signs like '+' at the start, or are split into parts with dashes or dots.\",\n    potential_improvements=\"Improving accuracy for specific country formats and adding validation for the total number of digits to prevent matching incomplete or overly long numbers.\"\n)\n\nurl_personal_pattern = RegexPattern(\n    regex=re.compile(r'\\b(?:https?:\\/\\/)?(?:www\\.)?[a-zA-Z0-9]+(?:[\\-\\.]{1}[a-zA-Z0-9]+)*\\.[a-zA-Z]{2,5}(?::[0-9]{1,5})?(?:\\/\\S*)?\\b', re.DOTALL),\n    name=\"URL_PERSONAL\",\n    description=\"Matches a wide range of personal URLs, with optional protocol and 'www' prefix, supports domains and subdomains, optional port numbers, and paths.\",\n    detailed_explanation=\"This pattern is designed to identify most personal website URLs, including those with or without 'http://' or 'https://', optional 'www.' prefix, domain names with possible subdomains, and even specific ports and paths.\",\n    step_by_step_explanation=r\"\"\"  1. `\\b` ensures we're looking at a distinct URL.\n  2. `(?:https?:\\/\\/)?` matches the protocol if it's present.\n  3. `(?:www\\.)?` optionally matches 'www.' at the start of the domain.\n  4. `[a-zA-Z0-9]+(?:[\\-\\.]{1}[a-zA-Z0-9]+)*` captures the domain and any subdomains.\n  5. `\\.[a-zA-Z]{2,5}` matches the top-level domain (TLD).\n  6. `(?::[0-9]{1,5})?` optionally matches a port number.\n  7. `(?:\\/\\S*)?` matches any path that follows the domain.\"\"\",\n    eli5_example_explanation=\"This pattern helps find website addresses in a big book. It can spot them whether they start with 'http://' or 'www', and even if they have extra parts like '/photos' at the end.\",\n    potential_improvements=\"Refinements could include stricter validation of domain names and TLDs, as well as improved handling of query parameters and fragments in URLs.\"\n)\n\nemail_pattern = RegexPattern(\n    regex=re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,4}\\b', re.DOTALL),\n    name=\"EMAIL\",\n    description=\"Matches email addresses, supporting a broad set of characters before the '@' symbol, and standard domain formats.\",\n    detailed_explanation=\"This pattern is geared towards identifying email addresses by matching a series of characters allowed before the '@' symbol, followed by a domain name and a top-level domain.\",\n    step_by_step_explanation=r\"\"\"  1. `\\b` ensures the match starts at a word boundary.\n  2. `[A-Za-z0-9._%+-]+` matches the username part of the email, which can contain a variety of characters.\n  3. `@` is the essential symbol separating the username from the domain.\n  4. `[A-Za-z0-9.-]+` matches the domain name, allowing letters, numbers, dots, and hyphens.\n  5. `\\.[A-Za-z]{2,4}` finds the top-level domain, which is between 2 to 4 characters long.\"\"\",\n    eli5_example_explanation=\"This pattern is like looking through a huge pile of cards to find the ones with email addresses. It knows an email has a part before and after the '@' and ends with something like '.com' or '.net'.\",\n    potential_improvements=\"Could be enhanced to account for newer, longer TLDs, and to better validate domain names according to the latest internet standards.\"\n)\n\n\nREGEX_PATTERN_LIST = [street_address_pattern, name_student_pattern, id_num_pattern, phone_num_pattern, url_personal_pattern, email_pattern]\nREGEX_PATTERN_MAP = {_pattern.name:_pattern.regex for _pattern in REGEX_PATTERN_LIST}\nUSE_ADDRESS_REGEX = True\n\n# Showcase a few of the attributes of our dataclass\nfor _pattern in REGEX_PATTERN_LIST:\n    print(f\"\\n\\nPATTERN NAME: {repr(_pattern.name)}\")\n    print(f\"REGEX       : {repr(_pattern.regex)}\")\n    print(f\"DESCRIPTION : {_pattern.description}\")\n    print(\"STEP-BY-STEP EXPLANATION:\")\n    print(_pattern.step_by_step_explanation)\n    \nif not USE_ADDRESS_REGEX:\n    _ = REGEX_PATTERN_MAP.pop(\"STREET_ADDRESS\")","metadata":{"execution":{"iopub.status.busy":"2024-02-17T20:34:05.621193Z","iopub.execute_input":"2024-02-17T20:34:05.621634Z","iopub.status.idle":"2024-02-17T20:34:05.650111Z","shell.execute_reply.started":"2024-02-17T20:34:05.6216Z","shell.execute_reply":"2024-02-17T20:34:05.648683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def is_start_of_sentence(start_index, text):\n     # If the character before the match is a period followed by space, newline, or tab, it's the start of a sentence\n    # Check the character(s) before the match to determine if it's the start of a new sentence\n    preceding_text = text[max(0, start_index - 2):start_index]\n    return preceding_text in ['. ', '.\\n', '.\\t', '\\n', '\\t']\n\ndef classify_tokens(text: str, tokens: list[str], drop_common: bool = True) -> list[str]:\n    \"\"\"Classify tokens from a text string based on predefined regex patterns, with precedence given to later patterns.\n\n    Args:\n        text (str): The original text to be analyzed.\n        tokens (list[str]): A list of tokens obtained from the original text.\n        drop_common (bool, optional): \n            - Whether to drop non-'O' classification for \n              the most common words in the train text dataset.\n\n    Returns:\n        list[str]: A list of classifications for each token, using the BIO tagging scheme.\n\n    \"\"\"\n    # Initialize token labels as 'O' for Outside\n    token_labels = ['O'] * len(tokens)\n    token_positions = get_token_positions(text, tokens)\n\n    # Track the highest precedence pattern matched for each token\n    token_precedence = [0] * len(tokens)\n\n    for precedence, (label, pattern) in enumerate(REGEX_PATTERN_MAP.items(), start=1):\n        if not isinstance(pattern, list): pattern = [pattern,]\n        for _p in pattern:\n            for match in _p.finditer(text):\n                if label==\"NAME_STUDENT\" and is_start_of_sentence(match.start(), text):\n                    continue\n                start, end = match.span()\n                token_range = find_token_range(start, end, token_positions)\n                if token_range:\n                    start_index, end_index = token_range\n                    update_labels(token_labels, token_precedence, start_index, end_index, label, precedence, drop_common, tokens)\n                    \n\n    return token_labels\n\ndef get_token_positions(text: str, tokens: list[str]) -> list[tuple[int, int]]:\n    \"\"\"Find the start and end positions of each token in the original text.\n\n    Args:\n        text (str): The original text.\n        tokens (List[str]): A list of tokens.\n\n    Returns:\n        List[Tuple[int, int]]: A list of tuples indicating the start and end positions of each token.\n    \"\"\"\n    positions = []\n    start = 0\n    for token in tokens:\n        start = text.find(token, start)\n        end = start + len(token)\n        positions.append((start, end))\n        start = end\n    return positions\n\ndef find_token_range(start: int, end: int, positions: list[tuple[int, int]]) -> tuple[int, int]:\n    \"\"\"Determine the range of tokens covered by a given start and end position in the text.\n\n    Args:\n        start (int): The start position of the match in the text.\n        end (int): The end position of the match in the text.\n        positions (List[Tuple[int, int]]): Token positions in the text.\n\n    Returns:\n        Tuple[int, int]: The start and end indices of tokens covered by the match.\n    \"\"\"\n    start_index = end_index = None\n    for i, (token_start, token_end) in enumerate(positions):\n        if token_end > start and (start_index is None):\n            start_index = i\n        if token_start < end:\n            end_index = i\n    return (start_index, end_index) if start_index is not None else None\n\ndef update_labels(labels: list[str], precedence: list[int], start_index: int, end_index: int, label: str, current_precedence: int, drop_common: bool, tokens: list[str]):\n    \"\"\"Update the token labels for a range of tokens matched by a regex pattern, considering common words.\n\n    Args:\n        labels (list[str]): The current list of token labels.\n        precedence (list[int]): The current precedence levels of token labels.\n        start_index (int): The starting index of the matched token range.\n        end_index (int): The ending index of the matched token range.\n        label (str): The label to apply.\n        current_precedence (int): The precedence level of the current label.\n        drop_common (bool): Whether to skip labeling common words with non-'O' classifications.\n        tokens (list[str]): The list of original tokens for reference.\n    \"\"\"\n    for i in range(start_index, end_index + 1):\n        if current_precedence >= precedence[i]:\n            # Check if token is a common word and drop_common is True; if so, continue with 'O'\n            if drop_common and tokens[i] in COMMON_TOKENS:\n                continue\n            if label==\"NAME_STUDENT\":\n                if \".\" in tokens[i].lower() or tokens[i].lower() in COMMON_TOKENS:\n                    continue\n            precedence[i] = current_precedence\n            labels[i] = 'B-' + label if i == start_index else 'I-' + label\n\n\n# Example usage\nprint(\"\\n... SIMPLE 'JOHN-DOE' EXAMPLE ...\\n\")\ntext = \"John Doe lives at 123 Maple St. His email is john.doe@example.com and his site is http://johndoe.com\"\ntokens = text.split()\nclassified_tokens = classify_tokens(text, tokens)\nprint(repr(text)+\"\\n\")\nfor tok, tok_cls in zip(tokens, classified_tokens):\n    print(f\"{repr(tok):>20} --> {tok_cls:<15}\")\n\n# Classify and show for train example\nprint(\"\\n\\n\\n... EXAMPLE FROM TRAIN DATASET ...\\n\")\nDEMO_ID = 1103\nclassified_tokens = classify_tokens(train_df.iloc[DEMO_ID][\"full_text\"], train_df.iloc[DEMO_ID][\"tokens\"])\nprint(repr(train_df.iloc[DEMO_ID][\"full_text\"])+\"\\n\")\nfor i, (tok, tok_cls, tok_lbl) in enumerate(zip(train_df.iloc[DEMO_ID][\"tokens\"], classified_tokens, train_df.iloc[1103][\"labels\"])):\n    if i==50: break  # Don't blowup the outpout\n    print(f\"{repr(tok):>20} --> {tok_cls:<15} --> {tok_lbl}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-17T20:45:45.582033Z","iopub.execute_input":"2024-02-17T20:45:45.582631Z","iopub.status.idle":"2024-02-17T20:45:48.041251Z","shell.execute_reply.started":"2024-02-17T20:45:45.582586Z","shell.execute_reply":"2024-02-17T20:45:48.039813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">6.2 <b>VALIDATION</b> ON TRAIN DATA</h3>\n<hr><br>\n\n1. Generate Predictions for Train Dataset\n2. Calculate metric\n\n<br>","metadata":{"papermill":{"duration":0.051114,"end_time":"2024-02-10T16:14:12.450119","exception":false,"start_time":"2024-02-10T16:14:12.399005","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**DO TRAIN SET PREDICTION IF NOT BACKEND SUB**","metadata":{}},{"cell_type":"code","source":"def generate_predictions(\n    df, classify_func: Any, \n    output_fname: str | None = None, \n    full_text_col: str = \"full_text\", \n    tokens_col: str = \"tokens\", \n    document_col: str = \"document\", \n    gt_col: str | None = None,\n):\n    \"\"\"Generate predictions for tokens within documents in a DataFrame and save to a CSV file.\n\n    Args:\n        df (pd.DataFrame): The DataFrame containing the data.\n        classify_func (function): A function that accepts two arguments (full text, tokens) and returns classifications.\n        output_fname (str, optional): The name of the output CSV file.\n        full_text_col (str, optional): The name of the column containing the full text.\n        tokens_col (str, optional): The name of the column containing tokens.\n        document_col (str, optional): The name of the column containing document number.\n        gt_col (str, optional): The name of the column containing the ground truth label\n\n    Returns:\n        pd.DataFrame: A DataFrame containing the predictions with columns for document, token, label, and row_id.\n\n    Example:\n        >>> test_df = pd.DataFrame({\n        ...     \"full_text\": [\"This is a test.\", \"Another test.\"],\n        ...     \"tokens\": [[\"This\", \"is\", \"a\", \"test\"], [\"Another\", \"test\"]]\n        ... })\n        >>> def mock_classify(text, tokens):\n        ...     return [\"O\", \"O\", \"O\", \"B-TEST\"], [\"O\", \"B-TEST\"]\n        >>> pred_df = generate_predictions(test_df, mock_classify, \"full_text\", \"tokens\", \"submission.csv\")\n        >>> print(pred_df)\n    \"\"\"\n    \n    # Generate predictions by iterating over zipped lists\n    full_texts = df[full_text_col].tolist()\n    tokens_lists = df[tokens_col].tolist()\n    preds = [\n        classify_func(text, tokens) \n        for text, tokens in \n        tqdm(zip(full_texts, tokens_lists), total=len(df))\n    ]\n\n    # Prepare data for the prediction DataFrame more efficiently\n    documents = []\n    tokens_idx = []\n    token_strs = []\n    labels = []\n    \n    # Iterate through each prediction and corresponding tokens to populate the lists\n    if gt_col is None:\n        for i, (pred, tokens) in enumerate(tqdm(zip(preds, tokens_lists), total=len(df))):\n            k = 0  # Use for vectorized append of document id\n            for j, (tok_cls, tok) in enumerate(zip(pred, tokens)):\n                if tok_cls == \"O\":  # Skip tokens classified as \"O\"\n                    continue\n                k+=1\n                tokens_idx.append(j)\n                token_strs.append(tok)\n                labels.append(tok_cls)\n            documents.extend([df.loc[i, document_col],]*k)\n            \n        # Create a DataFrame from the lists\n        pred_df = pd.DataFrame({\n            \"row_id\": range(len(documents)),\n            \"document\": documents,\n            \"token\": tokens_idx,\n            \"token_str\": token_strs,\n            \"label\": labels\n        })\n        \n    else:\n        gt_labels_lists = df[gt_col].tolist()\n        gt_labels = []\n        for i, (pred, gt_lbls, tokens) in enumerate(tqdm(zip(preds, gt_labels_lists, tokens_lists), total=len(df))):\n            k = 0  # Use for vectorized append of document id\n            for j, (tok_cls, tok_gt, tok) in enumerate(zip(pred, gt_lbls, tokens)):\n                if tok_gt == \"O\" and tok_cls == \"O\":\n                    continue\n                k+=1\n                tokens_idx.append(j)\n                token_strs.append(tok)\n                labels.append(tok_cls)\n                gt_labels.append(tok_gt)\n            documents.extend([df.loc[i, document_col],]*k)\n        \n        # Create a DataFrame from the lists\n        pred_df = pd.DataFrame({\n            \"row_id\": range(len(documents)),\n            \"document\": documents,\n            \"token\": tokens_idx,\n            \"token_str\": token_strs,\n            \"pred\": labels,\n            \"gt_lbl\": gt_labels\n        })\n    \n    \n    # Save the DataFrame to a CSV file if output_fname is specified\n    if output_fname is not None:\n        # If submission.csv we only include the columns we need\n        if output_fname==\"submission.csv\":\n            pred_df[[\"row_id\", \"document\", \"token\", \"label\"]].to_csv(output_fname, index=False)\n        else:\n            pred_df.to_csv(output_fname, index=False)\n    \n    # Return the DataFrame\n    return pred_df\n\nIS_BACKEND_SUB = len(test_df)!=10  # The test data will be much bigger if backend submission...\nprint(f\"\\n... THIS {'IS' if IS_BACKEND_SUB else 'IS NOT'} A BACKEND SUBMISSION ... \\n\")\nif not IS_BACKEND_SUB:\n    train_eval_df = generate_predictions(train_df, classify_tokens, gt_col=\"labels\")\n    display(train_eval_df)","metadata":{"execution":{"iopub.status.busy":"2024-02-17T20:46:03.318385Z","iopub.execute_input":"2024-02-17T20:46:03.318774Z","iopub.status.idle":"2024-02-17T20:46:06.701088Z","shell.execute_reply.started":"2024-02-17T20:46:03.318744Z","shell.execute_reply":"2024-02-17T20:46:06.699266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to process each group\ndef process_document_group(\n    group, \n    name_lbl: str = \"NAME_STUDENT\",\n    token_text_col: str = \"token_str\", \n    token_idx_col: str = \"token\", \n    pred_lbl_col: str = \"pred\", \n    keep_top_k_names: int = 4,\n    name_replacement_lbl: str = \"O\",\n):\n    # Filter for STUDENT_NAME labels\n    student_names = group[group[pred_lbl_col].str.contains(name_lbl)]\n    \n    # Find top-k most common raw strings\n    top_k_names = student_names[token_text_col].value_counts().head(keep_top_k_names).index.tolist()\n\n    # Replace labels for names not in top-k\n    group[pred_lbl_col] = group.apply(\n        lambda row: row[pred_lbl_col] \n        if row[token_text_col] in top_k_names or name_lbl not in row[pred_lbl_col] \n        else name_replacement_lbl,\n        axis=1\n    )\n    \n    return group\n\ndef refine_student_name_labels(\n    df: pd.DataFrame,\n    drop_all_O: bool = True,\n    keep_top_k_names: int = 4,\n    name_replacement_lbl: str = \"O\",\n    name_lbl: str = \"NAME_STUDENT\",\n    document_col: str = \"document\",\n    token_text_col: str = \"token_str\", \n    token_idx_col: str = \"token\",\n    pred_lbl_col: str = \"pred\",\n    gt_lbl_col: str = \"gt_lbl\",\n) -> pd.DataFrame:\n    \"\"\"\n    Refines labels for student names within a DataFrame by keeping only the top-k most common names\n    within each document and replacing others. Additionally, filters out rows where both predicted\n    and ground truth labels are \"O\" (indicating non-entities), and reindexes the DataFrame.\n\n    Args:\n        df: DataFrame containing the tokenized document data.\n        document_col: Name of the column in `df` that identifies each document.\n        pred_lbl_col: Name of the column in `df` containing the predicted labels.\n        gt_lbl_col: Name of the column in `df` containing the ground truth labels.\n\n    Returns:\n        A new DataFrame with refined labels, filtered non-entity rows removed, and reindexed.\n\n    Example:\n        >>> new_train_eval_df = refine_student_name_labels(\n        ...     train_eval_df,\n        ...     process_document_group,\n        ...     document_col='document',\n        ...     pred_lbl_col='pred',\n        ...     gt_lbl_col='gt_lbl'\n        ... )\n        >>> print(new_train_eval_df)\n    \"\"\"\n    # Check that it exists\n    gt_lbl_col = gt_lbl_col if gt_lbl_col in df.columns else None\n    \n    # Apply the specified function to refine labels within each document group\n    refined_df = df.groupby(document_col).progress_apply(lambda x: process_document_group(\n            x, name_lbl=name_lbl, token_text_col=token_text_col, token_idx_col=token_idx_col, \n            pred_lbl_col=pred_lbl_col, keep_top_k_names=keep_top_k_names, \n            name_replacement_lbl=name_replacement_lbl\n        )).reset_index(drop=True)\n\n    # Filter out rows where both predicted and ground truth labels indicate non-entity (\"O\")\n    # Reindex the DataFrame to ensure continuous row indices\n    if drop_all_O:\n        if gt_lbl_col is not None:\n            refined_df = refined_df[~((refined_df[pred_lbl_col] == \"O\") & (refined_df[gt_lbl_col] == \"O\"))].reset_index(drop=True)\n        else:\n            refined_df = refined_df[refined_df[pred_lbl_col]!=\"O\"].reset_index(drop=True)\n        refined_df[\"row_id\"] = range(len(refined_df))\n    return refined_df","metadata":{"execution":{"iopub.status.busy":"2024-02-15T18:18:17.071333Z","iopub.execute_input":"2024-02-15T18:18:17.071694Z","iopub.status.idle":"2024-02-15T18:18:17.089734Z","shell.execute_reply.started":"2024-02-15T18:18:17.071666Z","shell.execute_reply":"2024-02-15T18:18:17.088335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DO VALIDATION IF NOT BACKEND SUB**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import fbeta_score\nF1_BETA=5.0  # As per competition description\n\nif not IS_BACKEND_SUB:\n    f_beta_micro = fbeta_score(\n        train_eval_df[\"gt_lbl\"], \n        train_eval_df[\"pred\"], \n        beta=F1_BETA, \n        average='micro'\n    )\n    \n    print(\"\\n... F1-BETA METRIC ON OUR TRAIN DATASET (WEIRDLY LOW?) ...\")\n    print(f\"\\t--> {f_beta_micro}\\n\")\n    \n    new_train_eval_df = refine_student_name_labels(train_eval_df)\n    f_beta_micro_2 = fbeta_score(\n        new_train_eval_df[\"gt_lbl\"], \n        new_train_eval_df[\"pred\"], \n        beta=F1_BETA, \n        average='micro'\n    )\n    \n    print(\"\\n... F1-BETA METRIC ON OUR TRAIN DATASET (WITH POST NAME FILTERING) ...\")\n    print(f\"\\t--> {f_beta_micro}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-02-15T18:01:49.80772Z","iopub.execute_input":"2024-02-15T18:01:49.808206Z","iopub.status.idle":"2024-02-15T18:02:05.965199Z","shell.execute_reply.started":"2024-02-15T18:01:49.808174Z","shell.execute_reply":"2024-02-15T18:02:05.963031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">6.3 <b>GENERATE SUBMISSION</b> FOR TEST DATA</h3>\n<hr><br>\n\n1. Generate Predictions for Test Dataset\n2. Save to **`submission.csv`**\n\n<br>","metadata":{}},{"cell_type":"code","source":"test_submission_df = generate_predictions(test_df, classify_tokens)\nnew_test_submission_df = refine_student_name_labels(test_submission_df, pred_lbl_col=\"label\")\ndisplay(new_test_submission_df)\n\nnew_test_submission_df[[\"row_id\", \"document\", \"token\", \"label\"]].to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-15T18:21:57.241427Z","iopub.execute_input":"2024-02-15T18:21:57.242019Z","iopub.status.idle":"2024-02-15T18:21:57.616925Z","shell.execute_reply.started":"2024-02-15T18:21:57.241949Z","shell.execute_reply":"2024-02-15T18:21:57.615474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"next_steps\"></a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: #f4b37a;\" id=\"next_steps\">7&nbsp;&nbsp;NEXT STEPS&nbsp;&nbsp;&nbsp;&nbsp;<a style=\"text-decoration: none; color: #f8d2b0;\" href=\"#toc\">&#10514;</a></h1>\n\n<br>","metadata":{"papermill":{"duration":0.050461,"end_time":"2024-02-10T16:14:12.551233","exception":false,"start_time":"2024-02-10T16:14:12.500772","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #EB7550; background-color: #ffffff;\">7.1 <b>PLACE</b> HOLDER</h3>\n<hr><br>\n<ul>\n        <li>Placeholder 1</li>\n        <li>Placeholder 2</li>\n        <li>Placeholder 3</li>\n    </ul>\n<br>","metadata":{"papermill":{"duration":0.049999,"end_time":"2024-02-10T16:14:12.652385","exception":false,"start_time":"2024-02-10T16:14:12.602386","status":"completed"},"tags":[]}}]}